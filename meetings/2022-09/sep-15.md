# 15 September, 2022 Meeting Notes

-----

**Remote attendees:**
| Name                 | Abbreviation   | Organization       |
| -------------------- | -------------- | ------------------ |
| Bradford C. Smith    | BSH            | Google             |
| Kevin Gibbons        | KG             | F5                 |
| Michael Saboff       | MLS            | Apple              |
| Daniel Minor         | DLM            | Mozilla            |
| Kris Kowal           | KKL            | Agoric             |
| Mark S. Miller       | MM             | Agoric             |
| Mathieu Hofman       | MAH            | Agoric             |
| Waldemar Horwat      | WH             | Google             |
| Ron Buckton          | RBN            | Microsoft          |
| Justin Ridgewell     | JRL            | Vercel             |
| Istvan Sebestyen     | IS             | Ecma               |
| Philip Chimento      | PFC            | Igalia             |
| Ashley Claymore      | ACE            | Bloomberg          |
| Nicolò Ribaudo       | NRO            | Igalia             |
| Jack Works           | JWK            | Sujitech           |

## Temporal extension

Presenter: Philip Chimento (PFC)

- [proposal](https://github.com/tc39/proposal-temporal)
- [slides](https://ptomato.name/talks/tc39-2022-09/#15)

PFC: This should be very short. It's just the item from day one that we didn't achieve consensus on. In the meantime we've discussed it on GitHub and reached a resolution. So I'm presenting it again, hopefully for consensus and I hope that it won't won't even take the whole ten minutes. The outcome, the original normative change that I presented was to bring in the conclusions of the IETF draft for standardizing our annotation syntax that included the exclamation point which is a flag saying to the parser "You must not ignore this annotation". The discussion that we had with Jordan was about whether that flag should be preserved and written out on output. So that is a use case which may or may not appear as the flag gets adopted in the industry but everybody in the discussion has satisfied themselves that if we needed to do that in the future, it would be able to be introduced in a web compatible way, in a follow-up proposal. Whether that proposal is needed or actually happens depends on use cases that may appear in the future, but for now, we are confident that they can be handled without breaking the web. So there's no need to include them in Temporal right now.

PFC: Given that, I'd like to request consensus again on this single normative change in this PR here in the sides, temporal #2397. Just to recap what it does, that I talked about two days ago: it brings the syntax of time zone and calendar annotations in line with the new format that's defined in the IETF document, called IXDTF for Internet eXtended Date-Time Format. It enables an option in the toString methods of Temporal objects that allows you to specify that the flag should be output in the string, and it will throw if Temporal tries to parse a string with unknown annotations that are marked with that flag. So, are there any questions about this or things on the queue that we need to discuss?

SYG: I have a clarifying question about the implementation ramifications of this. To make sure I understand, what you're requesting consensus on is that there is an optional argument toString that would output the "critical" flags, which means that…. So FYT's disagreement with keeping all the optional flags was that we would need to keep a bit for every optional bracket, which is onerous. But the idea here is that the critical flags are the ones - there's some subset of those optional brackets, that the Temporal parser accepts because they're the ones that might have critical flags that we the Temporal parts of should not ignore. So, it would already need to have bits for those and those are the ones that are sensitive to this option in toString. Is that right?

PFC: I might not be understanding what you're saying, but nothing changes about the data model of Temporal objects. So no additional bits are needed for storing anything. Right now, an ISO string can have any number of annotations; those can be a time zone annotation, a calendar annotation or other ones that are not currently defined. Temporal only cares about the time zone and the calendar annotations, it ignores all the other ones unless they are marked as critical. In that case, it will refuse to parse the string if a time zone or a calendar annotation is marked critical. Then nothing happens because we already didn't ignore those, we already treated them as critical. So, at this point, this is purely a thing that you might want to add to a string for another consumer. Currently in the wild, there are no other consumers of strings that know about this critical flag. So there's no reason to do that at this point.

SYG: so, I think I'm just missing what the toString option was then? Could you please go over that again?

PFC: Sure I can actually go back to the slide that I had from two days ago. There's already an option for toString that lets you control whether the annotation its output at all. So you can hide the annotation if you are trying to give a string to a consumer that doesn't support the annotations in the first place. So this adds one option value to each of those options for the calendar annotation and the time zone annotation, that gives you the exclamation mark inside.

SYG: Okay. Thank you. Then I just misunderstood your update. I am happy with this. Thank you very much.

PFC: Okay. There's an item from DE on the queue: "Semantics of the critical flag seem reasonable to me. I support landing this patch. End of message." Thanks. All right. There's an item from JHD confirming as well. I'm going to go ahead and ask if we can call it. [silence] I guess that means consensus. Thanks everybody.

### Conclusion/Resolution

- Consensus for the proposed behavior in <https://github.com/tc39/proposal-temporal/pull/2397>

## Explicit resource management for stage 3

Presenter: Ron Buckton (RBN)

- [proposal](https://github.com/tc39/proposal-explicit-resource-management)
- [slides](https://1drv.ms/p/s!AjgWTO11Fk-TkoEvgEld8y2bGCjTlw?e=ySkk5z)

RBN: Hello everyone. I'm Ron Buckton from Microsoft. Today I will be talking about the explicit resource Management proposal. We've discussed this a number of times over the past few years, but to recap, the motivations for this proposal are to address a number of inconsistent patterns that are currently used for managing resources. This includes things like iterators, for of, spread, all use iterator return. WHATWG stream readers have released lock, node js. FileHandles have `close`, Nodejs streams have `destroy`. There are a number of different ways of determining, whether or not resources that you're currently actively using can are no longer necessary to be used and can have their native file handles released or etc. Another motivation is to manage the scoping of resources and handling that resource's lifetime. This currently is handled today with things like try-finally, where you create a handle or access to the file system handle and use it within a try block. And then use the finally block to manage closing it. but this can be problematic. This can be problematic, because of a number of common foot guns. it's often the case where someone will access a resource and then not have a try-finally, so that that resource isn't closed. They might have a try catch somewhere else in their application to continue execution, but they've potentially left open file handles that could cause other issues with race conditions with other file system accesses or just leaving open large objects or memory that is - large. amounts of memory that are held via native file handles or handles into wasm, etcetera. Another foot gun we commonly see is accessing multiple resources and then trying to use try finally. but either closing them out of order, or closing one but it throws. So then the second resources is never released. So, you're still leaking file handles and keeping things open in memory. and, one other motivation is trying to avoid the lengthy code that is necessary when trying to manage these multiple resources correctly. So you end up with access one resource. But it a try, finally excess the next resource. But that in a try finally, and even with this, we have issues with the exception that you might have in the inner try block, could possibly be swallowed or suppressed by exceptions that are thrown in the finally block. So it's hard to report on what was the original reason why something failed.

RBN:To address these we looked into mechanisms to define the explicit lifetime of a resource and both declarative and imperative ways of managing that resource that are consistent across different types of objects.

RBN: So we have a couple updates that we've made to the proposal since it was last presented in, I believe October of 2021. One is we have a container object or set of container objects that are used to hold on onto disposable resources, both synchronous and asynchronous resources. The naming has undergone some changes since the last time it was presented. and we've kind of narrowed down on the specific API. they're currently called DisposableStack and AsyncDisposableStack and I'll go into a little bit more detail about what those APIs look like a little bit further on the slides.

RBN: Another. change that we've made, we've gone through a couple different evolutions of the Declaration that we've considered. One suggestion that was provided on the Repository several years ago now was to introduce a specific declaration, just like we have `var`, `let`, and `const`, having a `using` keyword-based declaration. and, we've been considering that we get originally switched to `using const` rather than just `using` because of wanting to disambiguate if you had destructuring. But then it was later determined through various discussions that destructuring is actually really unsafe within a `using` Block. It's hard to determine what the thing you're destructuring, what should be the resource that's tracked. Whether or not in the middle of destructuring a resource, you might have an exception that's thrown as you step from one item to the next. So, as a result, you might lose information about that resource or not properly dispose of things. So we determined to drop the ability to destructure some time ago. And as a result, the parser ambiguity that we would have had to use just these simple `using` keyword is removed because we don't have to worry about it looking like an element access. So, this simplifies the `using` declaration.

RBN: Another. change that we recently made or made prior to the October discussion was to focus on using RAII resources by using block scoped using declarations. This simplifies the approach that we originally had with the using statement, which had something akin to a for Loop style head that allowed you to declare the variables that were used in the block. the RAII Style. is much more convenient when writing code you don't have complex nested block. When you need to create one resource, do some work, create another resource. Everything is still bounded to the block scope.

RBN: Now there are a couple things that we've had in this proposal for some time. In an effort to kind of focus on a minimum viable version of this proposal we've decided to postpone or drop specific functionality. Postponed features we still plan to continue investigating and potentially ship or proposed, as separate capabilities, as following proposals. Anything that's dropped is something that we're not considering pursuing. One thing that we are planning to propose is the bindingless `using void` declaration, There are several reasons for this. I'll get into those more a little bit later. We're dropping the using await declaration or the RAII style for using await. I will get into more about that, as well. Postponing the `using await` statement form and either postponing or dropping just the `using` statement form. And I'll talk about more More. about those here, shortly.

RBN: To kind of get into the meat of what the proposal looks like today. I'll talk about `using` declarations. so, the idea of the `using` declaration is, you are declaring an immutable - and by immutable I mean constant - block scoped declaration That is that acquires a resource. you can execute any expression. and the result is something that has a `Symbol.dispose` method. or null or undefined. any resources that are captured are then tracked to be disposed at the end of the block. This occurs in block statements, this occurs in for loops. So in a for statement, you could use a using declaration in the for initializer. This would be scoped to the entire for statement, it is not per iteration, and this is the same behavior. we have for const variables as well. We only create per iteration bindings for let variables in a for Loop. in addition, using declarations in the head of a for-of or for-await-of are possible. And those then become scoped to each iteration. Thus, they would dispose at the end of each iteration of the loop, or if you break early.

RBN: So `using` declaration semantics. the statement is again essentially - `using` is a contextual keyword, essentially, followed by an identifier, and an initializer and then a comma delimited list of additional identifiers and initializers. These produce immutable or constant bindings. We chose this, It's consistent with several other languages that have similar capabilities, primarily so the Declaration that you provide should not change, which would be confusing to the user as to what then gets disposed at the end of block of the can change. The lifetime of the value is scoped to that declaration’s block scope container. that helps again to receive reduce excessive block scope nesting that occurred with the using statement. Binding patterns are not permitted for the reasons I mentioned before. We do not permit this at the top level of a script, because of the complexities of declaring variables and then determining what is the appropriate lifetime if they are global? We discuss this at the last meeting and I believe reached consensus to ban them at the top level of script. They are allowed at the top level of a module because those have an implicit block scope. We dropped the `const` for a number of reasons. It's essentially unnecessary boilerplate at this point. helps to differentiate using from let const. for a number of reasons, one that there is specific semantics behind the variable and because we don't allow binding patterns. So there is enough of a reason to have a way to distinguish this. This is very similar to C++'s stack variables and C# 8's `using` declarations.

RBN: so, I'll go to a couple more things here and then we can talk about some of the things that are currently in the queue. So `using` declarations, as they're currently written in the spec to support for-of and for-await-of, just like with the normal `using` declarations, these would produce immutable or constant bindings, and disallow binding patterns.Iin a normal for statements, the using a scope to the entire statement. Again, this is consistent with how const works. We do not create per iteration bindings for constant variables. because this value cannot change over the course of every iteration within that Loop, it does not get disposed until the entire Loop completes or breaks. In. a for-of or for-await-of, the lifetime of the using a scope to each iteration because you are the using declaration receives the value. That is being iterated, That value, then might we would want to have a lifetime that is scoped to the iteration for each one of those. And again, it's still immutable, We don't support it for-in because you cannot produce a value with for-in that would ever be legal for using. Strings cannot be disposed. We only disposed. objects with `Symbol.dispose`. method. The other thing to note is that disposal in a for-await-of is still asynchronous. This does not use the async Disposable feature. and this is just because we don't have a current syntactic mechanism that works with asynchronous disposables, which I'll discuss a little bit later.

RBN: Before. I continue, there's a number of items on the Queue. I'd like to get to as they're related to these specific slides.

MAH: I was wondering what happens if there is a `using` declaration Inside of the block of a for-of Loop.

RBN: it would be scoped to that block execution. just like introducing a const, the constant value. value if you have a const declaration inside of that block, it is only constant. within that iteration of the loop. the next time you go through the loop. It is then essentially reinitialized. and you can. reintroduce, a value for The Binding. In the same vein, a `using` declaration would get its value inside of that block And when the block exits, the value would then be disposed.

MAH: so it would just be stacked on top of whatever using Declaration was in the for `using X`. If you have a `using y` it would dispose of Y and then dispose of X in the same the same stack.

RBN: Essentially. there might be semantics around the aggregate - how the exceptions look but essentially, yes, It's as if you'd had the, the `using X` outside of the, in a separate block outside of the current block and then the `using Y` inside of the new block the using Y would be scoped to the inner block in the using X is scoped to the outer block.

MAH: Interesting? Okay. Thank you. you.

JHD: I mean it's not the only motivation, you've expressed but one of your earlier slides. had an example where they should have used try finally And they forgot to. If they're not going to remember to use that then what's going to help them remember to use `using`?

RBN: the best thing for that is - well for one, it's, if you have documentation and examples or stack Overflow posts that people are showing. How do you use this thing, getting kind of a once this becomes available and the community is able to leverage it and start using it, it can become a best practice. in addition. it's possible that linters and static analysis systems like TypeScript or flow can warn on not disposing. You. or we're using it in some way that keeps track of it in general. There is no mechanism to specifically say You must dispose, there’s just no mechanism in ecmascript that says You must iterate an iterator. iterator. So if create call the generator and don't next it, we don't do anything to tells you not to do that, but we are hopefully providing something that will be very easy to use and then can be referenced in the documentation for the things that then support disposable.

JHD: Thanks.

WH: You mentioned that destructuring is not supported; however, the destructuring syntax is valid and will just do something else. `using` is not a reserved word and I don't see any attempt here to try to reserve it. If you write array-based destructuring, it will assign to a variable named `using`.

RBN: Yeah. one reason to not ban it would be to not break existing code. The form of "using space identifier" isn't currently legal and there is potential for someone writing. "using[whatever]" and making it look like an element access. And we're not again, we're not doing anything specifically to ban this. So as to not break existing code.

WH: Okay. That's fine since I don't really expect people to write this unless they're looking for it.

JHD: My next item was, if you `using` something that isn't disposable, then what happens?

RBN: I do have slides coming up that explain that. I will get to that in a moment. So I wanted to specifically address some of the things that were on here.

MAH: I find the `for (using x;;)` semicolon form being per-iteration confusing. actually, when I reviewed the slides, I somehow thought it wasn't. that it was per iteration. and I don't really see a good reason to allow it. I think it should just be made illegal. to use a `using` it in a for statement like that.

RBN: Yeah, there is an issue that was opened on an issue tracker to discuss that on the issue tracker. my rationale to include it is that we don't make const Foo illegal in the in a for Loop and const few is not per iteration. if you look at the specification, text we only create per iteration bindings for `let` variables. Yes. Eels. So it is consistent with how works. Today, we're actually right and those constant value a constant value in the head cannot change each within each Loop.

MAH: Nobody really writes a `for const`, they will very quickly realize that they cannot reassign it. I don't know.

KG: You are correct as a matter of what the specification says that `const` is not per iteration, but it's not observable that it's not per iteration. It might as well be.

RBN: Except that you don't reevaluate the thing that you store in the const.

KG: You don't for `let` either.

RBN: Well. that's true but let can't change. const values. Cannot so it's right. I think it's not exactly observable but it is… I, again, left it in for consistency with const. If it's necessary to achieve consensus to remove it. that's definitely something that I can look into.

MAH: Yeah. I think it doesn't really serve a purpose. So if it's just for consistency with const, I don't think that's good enough of a justification in my opinion. Looks like WH disagrees.

RBN: My biggest concern. And I mentioned this in the issue tracker is that banning it seems somewhat arbitrary when we do allow const, and there is a way to do it without `using`, which is to create a block then declare the `using` then create a `for` that has no initializer. and that's not really that obvious to a user when we could allow `using` just where we allow const. So it seems like it's a somewhat arbitrary choice to not support it that could possibly be confusing to users.

WH: I agree with RBN for the same reasoning that RBN just stated. I think it would be gratuitous to ban `using` from the first substatement of a `for`. That thing is understood to only run once. Because `const` is allowed there, it's pretty clear that that thing is run once.

RBN: So, I'd like to continue with some of the slides and we can come back to some more comments as we go because I think some of the things I have coming up, we'll answer some of the open questions.

RBN: So, one of the things that was on the on the Queue was what are the semantics for dispose. So the here with a `using` declaration, the value expression can be null or undefined, which reduces the need for complex branching. We've had some discussions on ways you could do this with a switch statement that aren't exactly clear, easy, or obvious. And some of the prior art that I've referenced allows you to have null or undefined so you can conditionally have resources but not necessarily need to have very complicated block nesting. would be necessary. to declare a `using`, but only in certain cases that has the same lifetime as all the rest of your code or have to duplicate your code etcetera. In the case where the value is neither null or undefined we read the `@@dispose` method. So, if it does not have a callable @@dispose method, we throw a TypeError. This ensures that the resources properly disposable before we execute code that uses it. This was an explicit request on the issue tracker from a number of individuals have used this similar behavior that we have this early check. When we pull off the dispose method, we track both the expression's value, and the dispose method in the stack in the current lexical environment. So that when the block exits, we can then evaluate the dispose against the value.

RBN: Another thing that we've kind of discussed in the past is what the semantics are when there are exceptions. So, in this example, you have a using declaration for some resource with a dispose that will complete successfully at line A. At line B here. An exception is thrown from user code and as we exit the block at sea, we will attempt to disport dispose. The resource that we recorded a day. In this case, all calls to dispose complete without error. And since the completion from be was a throw completion. There were no other errors during disposal, we'll just propagate that throw completion. So, the error that was thrown here will be the one that is potentially caught fire at the stack. However, if there is an exception that occurs during dispose, we will then track and throw currently an aggregate exceptions for the current proposal specification. In this example, again, we create access disposal resource in this case, it will for some reason throw an exception, when it's exposed. because the user code later in the block continues without error, when we exit and call the dispose method. When this throws, we end up throwing an aggregate exception that contains whatever errors came from dispose. One of the things that we want to try to do is avoid suppressing exceptions, so that you can observe both exceptions that are raised by resources when they are they are disposed as well as whatever exception may have been originally throwing the block. As a result, we're currently using aggregate exception. and this example shows here that we would end up throwing an exception at B, also throwing one from the resource when we dispose, and the errors for that would end up in error collection and aggregate in the exception and the cause on that. Exception would be the original error from the throw completion. There was a question that came up. we discussed and it's related to the issue that WH had about blocks and observability. One thing that is currently a potential concern is having a `using x` on a line and `using y` on a line. And if you were to put that `using y` in a new block that would change the shape of the exception that is thrown. We do have an issue on the issue tracker to talk about various ways, this could be addressed. the current solution. is that you could end up with an aggregate exception that has an errors, that contains another aggregate exception. and from last discussion I believe JHD advocated for leaving it as is as it's reasonable. Aggregate exceptions are essentially a container exception. so, I know that's something we'll probably discuss a bit more as well as we get towards the end of the slides.

RBN: There are a couple other open questions that have been raised. one is issue number 97, which is whether a `using` declaration should become unusable after the block scope exits. Essentially introducing a new TDZ. I'm not really all that comfortable with this. Objects that are disposable should still defend against access that's inconsistent with the current state. So if you have a connection that is open and you close it and then try to access connection-specific properties while it is closed, those should throw regardless of whether you use `using`. Since those already should be defensible against this inconsistent state. Uninitializing the value isn't necessarily very useful. In addition, there's a number of cases of disposable objects that be reused. You could have a connection that you open it when you dispose, you close it. But then you could reopen it in addition, you might have useful properties that you want to be able to access such as the URL or status code of an HTTP request After the resource has been disposed, you might still want to be able to access those. those. Yeah. a call back the disposed objects reference is still valuable if you put the object in a cache and they want to have a periodic sweep of the of the cash to remove still references foreclosed resources. and the workaround for this would, if we implemented this would be to create a const variable, that is an alias to the using declarations variable just so that you can access it after the fact. It's not very discoverable or easy to use. And again I am not terribly comfortable with introducing a new TDZ. I would like like to avoid it if possible.

RBN: Another open question was whether it was related to error suppression. So a lot of this proposal is based on prior art in C# and C++, but also within python. in Python, they have a version of essentially, what is disposed with the **exit** magic method. It's similar to dispose, but it also receives the suppressed exception and you can return true to suppress the exception at the site where it was thrown so that doesn't actually throw. It's as if you had a catch and handled it, and there was a question of whether we should consider supporting this for disposed. I'm not inclined to support this capability. At least not for dispose. Dispose is essentially lightweight. There will be a lot of objects that could be, It could have a disposed method that would be called that have absolutely no need to know about the exception that was thrown. don't need to inject themselves with in the exception, catch and throw Mechanism. So, I'd be wary about the overhead. That would be incurred by passing along kind of information of each call. And if we did decide to have it in the future, I think a future, follow-on proposal that adds a different symbol-named method to specifically opt into that capability is feasible and could be added to support for using but it's not something I think. I'm interested in pursuing within the proposal itself. That said, there are some interesting things you could do if you had this.

RBN: So the other thing that I wanted to discuss that is currently in the proposal are the Disposable and AsyncDisposable interfaces. I'm talking about these spec definition of an interface, we have. just for iteration of as well. So, the Disposable interface just a describes, an object that has a dispose method. Invoking the dispose method indicates the come to, the caller, doesn't need to use the object anymore. Its resources can be freed. again, symbol disposes used by the using declaration. It's also used by the Disposable stack class. So when in exceptions were thrown from dispose, it typically indicates, the resource could not be freed. There's some type of opportunity to perform additional logic or reporting to handle those cases. When call it should perform all necessary. Cleanup logic, it's not necessary - There is no way that we can explicitly enforce that. and there are actually a number of use cases where you can create disposable objects that have nothing to do with resources to leverage the dispose of mechanism, logging and transactions and other cases that are very valuable use cases as well. So it's not something that we would be looking to explicitly try to enforce. Also. when called the dispose method should avoid throwing exceptions when the method is called more than once, but this is again not enforced and not required The idea being that a, a well-written disposed method will check to make sure that if it's already been disposed of through an imperative call to dispose, then it won't also throw at the end of the block because of the `using`'s evaluation of dispose. The AsyncDisposable interface is the same as Dispose, but it's designed to work asynchronously much like asyncIterator is the asynchronous version of the iterator method. In this case an async disposal method can return a promise that could be rejected if it fails. But again, it has pretty much the same recommendations for use as the dispose method.

RBN: And then in addition to the using statements use of dispose, the disposed in async disposal methods can be used by API that I discussed earlier, which is the DisposableStack and AsyncDisposableStack classes. The DisposableStack class is a new global that we are proposing to introduce which is a container for disposable resources. It has an API that is somewhat similar to python's ExitStack that is part of its context lib. a disposable stack Aggregates multiple disposables so that if you are building a class that references multiple resources then you want that class to also be disposable and have consistent semantics for how those resources should be disposed in the right order. This provides a way to aggregate those and handle that composition. It is also provides interop for non-disposable resources. through the use with a resource and a non-disposable call back. I'll describe that bit more in a moment. It. also, assists with complex construction and classes to create multiple resources and it is called a stack for the reason that resources are added in a certain order and they are then disposed in the opposite order. They were added just as the `using` declaration. As far as. the methods on the class, the use method has two modes of operation. One is using a disposable resource - I should say, three modes actually. One is just accepting a disposable resource to `use`, much like a using declaration. It can be null or undefined. if you pass a callback. The. does not itself have a disposed method on it. It is used as if it were a dispose method on an object. And this allows you to do things like emulate goes, defer, adapt. existing APIs that aren't they don't currently match the Disposable semantics. The. other mechanism for this is to pass a non-disposable resource. with a on disposed call back and this is again a way to adapt resources are not currently designed to work with dispose. In allows you to take any resources or any value you want. to add to add it to the Disposable stack and the on disposed callback is called when that needs to be cleared. Please. a brief example of of the use method here. You could have a stack, you could assign resources to with use. the resource that you add is returned. You can use callbacks, you can use non-disposable values, and those are all disposed in reverse order. The next method that's part of this is called the move method. This moves resources out of the current disposable stack and into a new disposable stack that's returned. This is very useful. When working with class constructors to compose subordinate resources. That's difficult to kind of reason over. So here's a very useful example. So in this example we have a PluginHost that is going to create something that uses an IPC Channel over the standard input and output. and then create an IPC socket wrapper around that channel. without disposable stack, if were to just use `using channel = resource`, `using socket = resource`. You run into a number of issues, one. Is that if you have no way to then, store the channel and socket on the class, because they'll be me too. disposed as soon as the Constructor exits. So if you were then to instead just do assignments on the class, if an exception occurs during construction of the socket, the channel wouldn't be disposed. And that could then potentially lead to leaking a handle or leaving open a resource that could cause a race condition.

RBN: To finish this example. What this does, then the to if you're to just do the assignments, you run into issues with exceptions then we're back to the again initial motivations of having to wrap these all with dragons and finally is to reach the end. instead. This simplifies this process, you create a stack that is scoped to the Constructor. You can use these new resources to get added. So if an exception gets thrown during construction of these resources, as the block exits, the stack will be disposed, which will dispose of the resources You've tracked, successfully. Once you have created all these resources successfully you can then use the move method to pull them out of the stack that is guaranteed to be disposed, and put them into a new stack that you can then dispose later. These again ore capabilities are also available in python's ExitStack. The last API method is the public dispose method, which is essentially a bound dispose. The this was a request on the issue tracker for folks that want to use the same type of capabilities, but within a factory function where they just want to use the bound dispose. This is something that I think is very useful but there's been some discussion about whether it's necessary. So, So, I don't. have a strong need for it, but I felt that it was valuable to consider. And AsyncDisposableStack is very similar similar to the DisposableStack, but is designed to work with async features.

RBN: so, I did want to talk about the postponed features, but I don't know how much time I’ve got. [discussion of timebox]

RBN: Well, the one thing that I wanted to get to. So `using void` I've discussed, I think it's valuable, We can discuss that a bit later. The `using` statement is something that I'm going to postpone or possibly drop. `using await` would be syntactically the syntactic form that we're considering for working with async disposables. and one of the reasons why this proposal still has async disposable stack even with deferring the async version of using is that asynchronous disposables are extremely valuable. They exist within the ecosystem with async iterables there's a number of use cases for these and AsyncDisposableStack provides a good middle ground for not yet. Having a syntactic mechanism of await that would be necessary. See. manage the implicit await, that we be concerned with So with that, I will go to the queue and we can talk about what we have here.

WH: My concern here is that, as I wrote in the queue, enclosing statements in their own blocks subtly changes in the runtime behavior in rather unexpected ways: `{stmt1; stmt2;}` visibly executes differently from `{stmt1; {stmt2;}}`. Fortunately, there is a simple solution to that, which is to run the logic of *DisposeResources* one error at a time rather than combining all the errors from a block and doing them together. If it could fully process errors one at a time, that would solve that problem. I’d like to hear RBN's opinion on that.

RBN: Are you talking about having a deeply nested AggregateError that only contains a single error in the errors array for each item from dispose?

WH: Yes.

RBN: That is potentially viable. It feels a little bit like unnecessary overhead. but it depends on whether it's necessary. is considered something to be necessary to maintain. maintain the option. graph in some way relating to the disposer graph. My only concern there is that you wouldn't necessarily have a aggregate exception for every single nested level that has a using if not every using through So I'm not sure that I find that. particularly valuable since you can't necessarily exactly reason over what that graph is going to look like.

WH: Well, it's precisely the point that the aggregate error *not* reflect the lexical count of how many blocks you have in your code. It would be an anti-feature to have it reflect the block structure of your code. The shape of exceptions objects should only reflect the *order* in which the errors arose, not how many blocks there are between one error and another.

RBN: I think that is something we've been discussing on the issue tracker and something that we can continue discussing there I guess. I don't really - because, of the fact that the shape can be arbitrary anyways, I'm not sure that I see the value of not nesting or not collecting all of the errors in a single aggregate error. But I appreciate the feedback.

WH: I don't think you're understanding the problem here. I also had raised it on GitHub.

RBN: I believe I do, but [crosstalk]

MAH: I guess. I have a specialized Case of this were in the `for using of resources` and then a `using` statement inside the block there would be nested aggregate errors, which as a user I would find weird. And I'm wondering if at least in this specific case, we might be able to avoid this. That's just a comment. I'll go to the I'll try to find the issue on GitHub.

KG: So I think this is probably not going to come up that much that you have a bunch of different errors. So I am not worried about having potentially deep structure, like three different errors that all need to get aggregated into a deep structure instead of a broad structure - that just doesn't seem like a big problem to me. I also think it seems like it would be nice to just not use AggregateError at that point to just say that the disposal error was caused by the original error, seems like it makes more sense for things that happen at approximately the same time. So, I wonder if there's the possibility of using error cause instead of aggregate error. But my main point is just I'm not worried about having deep structure and generally agree with WH’s point.

RBN: The reason why I would want to avoid using error cause, is that, that can be set by the user and we don't want to overwrite it. So we would need some intermediary, Exception object to represent the exception thrown from dispose that could also have a cause. And the Options. thrown by the user that could also have a cause whether that is aggregate error or something else, I don't have a particular preference.

KG: Ah, that makes sense.

SYG: +1 to WH's point about that we should fix this if possible, and also +1 to KG’s point. with my implementers hat on I'm not really that concerned about the overhead. We usually don't optimize or design something for the error case. So, it's perfectly acceptable to me, that if there is a long chain of errors in the errors, in the error case that that's accepts that's perfectly acceptable over him.

RBN: I appreciate that. Thank you.

JHD: It's doesn't seem to be relevant still, but the I just want to clarify at least from my perspective that I think aggregate error, its intended for anything that has multiple causes And so it's the at the same time to me at least is not a part of the mental model there. That's all.

RBN: It seems to me that the resolution to this would be the deeply nested aggregate error, which would satisfy most of the concerns.

WH: That's the simplest solution. The other solution, which I don't like as much, would be to de-nest so it's either perfectly shallow or perfectly deep. I just don't want a combination of the two based on the block structure of the code.

RBN: the issue with then being knowing whether or not the aggregator was raised by a disposed. Yeah, by using statement or by a user, because you wouldn't want to unnest an aggregate error that might have a custom message or anything like that.

WH: Yes.

RBN: I did. have a discussion of on the issue tracker about the potential of a future Edition to something like a `flatten` on AggregateError to create a flattened aggregate. Are this is actually something that C# has on its aggregate exception. That might be worth considering even if we just do the deeply nested aggregate are. It's mmm. Just as a way to more easily reason over these aggregate exceptions.

DE: Damn. Dan. Thanks. So the one thing that I hadn't realized before this presentation and apologize for not figuring out and filing issue before was the use of the ability to use `using` on things at the top level of a module. And I was wondering if disposal is ever called on those.

RBN: Yes, it is called as soon as the last line of code in the module, just, execution because the module has implicit block scope.

DE: Oh, Okay, so those are things that alive just during the initialization, okay? That makes sense. And that's useful.

RBN: and the spec explicitly bans exporting `using` declarations. You can't export using even though you can export const export let, you can't export using.

DE: Okay, great. since yeah. to export a resource that ends up being disposed soon as a module finishes up evaluation.

DE: Yeah. this this proposal seems really great. I'm very happy with the changes. You've you've been making and I support advancing. advancing. Thanks.

KG: So on the point about having the new TDZ, I'm the one who raised the issue and I do think that having a TDZ for these bindings after they have gone out of scope is worth doing. I really don't want to have an entirely new class of use after free. It's potentially useful to refer to the object that is used, but it's the binding that goes out of scope. The point of the RAII style is that when the binding goes out of scope, you are done with the object. You said that in so many words at a later point - “when the disposed method is called, you are done [with the object]”, and the that is the common case, and I think that avoiding issues where you accidentally close over in a setTimeout or whatever and then attempt to still use the binding, is sufficiently annoying that we should guard against it even though as you say objects ought to guard against it themselves. It just seems weird to have a thing that is explicitly. “Now I am done with this” and then in fact, you can still access it and not get an error.

RBN: Yeah. As I've seen with, I'd have strong reservations about introducing a new form of tdz. and there's other examples on the Queue of implementers that have strong concerns about it. I do have a PR up against the proposal that implements this, It is really awkward because you have a whole bunch of new things to the lexical environment to track these immutable but potentially safe to unbind resources. I'm not particularly comfortable with introducing a new tdz just for this specific purpose.

SYG: I strongly disagree with. doing the TDZ here. I don't think that's the right cost benefit for the foot gun of closing over `using` bindings. These aren't actually stack bindings. These adhere to a scope exit call this method kind of protocol. I would not want to bake dominant use into something so deep into the language, as TDZ. And TDZ has I, think currently there is no way to transition back into TDZ once a binding is out of tdz. I don't really want to open that can of worms. Like I haven't thought that through and I don't think it's worth thinking that through. this use case.

KG: I didn't understand that at all. Can you try a different way of saying the whole thing?

SYG: Are you saying that using bindings should be stack bindings?

KG: I am saying that you introduce them, you use them for the life of the block and at the end of the block you are done with it. That's like definitionally what they are, you dispose of them at the end of the block. that's literally what they are.

SYG: what they are is the end of the block is disposable. method. that most the time disposes of resources. I don't want to bake the use resources and dispose them use case into the language. at as at as deeper layer as TDZ. Like there are other use cases for calling a scope exit function. That is not just disposing resources.

KG: What is the use case for still referring to the binding after the scope exit method is called?

SYG: RBN lists them. You can see I mean you can have the position that you just disagree, and think those use cases are not useful. but I think those use cases are useful.

KG: It's not just that I think they are not useful. It's that I think they are super misleading. This is an attempt to use the binding after it has been disposed of. The point of the binding is that it is live for the block. that's literally the point of it.

SYG: The point of it is to register it to have a function to be called on it on scope exit; the majority use case of it is to dispose of it. That the point of this,

KG: It's literally called dispose.

SYG: Granted, that's true. but, Awesome. like, Semantics of it not that it Cannot. only be used for that, use case, perhaps should be called scope exit or but, I mean, I don't think it's a good name either. Yeah,

RBN: Say that there are a lot of cases in C#, for example, where the disposed method which is called dispose is used for things that do not have anything to do with resource acquisition and release. Because it is a very convenient pattern to use for things like defining. transactions for asset, Is it? three phase commit. It's very useful for doing, enter and exit logging. So, there are a lot of valid use cases for disposables and `using` that don't necessarily mandate making that value unreachable. where whether that is unreachable or not. is completely orthogonal to those use cases.

KG: For it to be important that the binding remain accessible, It's not just that this has to be a use case unrelated to dispose. It's that this has to be a use case unrelated to dispose where you still want to keep this specific reference to the thing. If it's just like context logging, that's not this. Like it is very specifically – to run into the error that I am proposing, you have to create a closure inside of the block, which refers to the `using` binding and then you have to invoke that closure sometime, after the end of the block, and like, we know, we have decades of experience from people doing a setTimeout in a for loop that they just fundamentally will not understand that this is leaking the Binding, that it is using a resource after it's no longer theirs to use.

SYG: So, KG, there's this slide which I agree with from kind of, the language design perspective, the use case perspective there on is presenting. then the second part of my queue item here was there is this property currently that something does not come back into TDZ. This. property makes optimization of tdz somewhat possible, granted currently in all implementations, that I know of closing over something combined with the fact that function definitions hoist make elimination of tdz, very difficult. but, nevertheless, there are attempts to get rid of tdz checks on every lexical binding Access in the implementations. To add another dimension to that by having `using` bindings being able to back into TDZ is something I am strongly against, like, not only am I convinced by the use cases here, I really do not want to implement this Behavior because I think it has other Consequences. I haven't done it and I haven't thought it through. I can't really say what it is but from past experience of implementing TDZ and lexical bindings from es6. It was not a good time, like I really don't want to make this more complicated for bindings.

KG: I really don't want to introduce an entire class of use after free bugs, so we will have to fight that war.

SYG: but this is not use after free. That's the point. This is not about freeing resources. Sorry, this is not about free memory.

KG: It is literally about like the mainline use case for this. The name of the symbol for it and the overwhelmingly most common use case for it is that you acquire ownership of a thing possibly by creating it yourself, and then use it for a while. So you are using it within a block. And then at the end of the block, you are done with it, you dispose of it by calling the dispose method. And to use it after that point - I agree there are some cases where that is not an error, but I think that in the overwhelmingly common case that is going to be an error. And I'm comfortable calling that a use after free.

SYG: so your you believe that…

BT: sorry to break in, we're about 10 minutes over time box. Maybe we could. let this run into lunch and still not extend into tomorrow?? Okay, so if we can still do your other item before lunch then would be ideal.

RBN: The question would I would have would be whether or not the TDZ concern is it would be something that would result in blocking because it sounds like the implementers are extremely against it.

SYG: To be fair, Neither Apple nor Mozilla have expressed concerns here. I don't want to say implementers but I don't know if anybody from SpiderMonkey is here.

KG: For what it's worth. There's a lot of stuff in this proposal that I only started reviewing in detail like ten days ago and I would be happier with this going for stage 3 at a later meeting anyway. just so that there is more time to think about all of it. I apologize for not being up with all of the changes. all of the time. but I don't want to block if I'm the only person who has this concern, but the shape of the proposal radically changed recently. I would be happier thinking about it in its current state for a while,

RBN: I'd like to clarify that the only radical change was removing features that we had decided to have been discussing postponing the actual core implementation hasn't changed really in about three years. Since. has changed a little bit, but the actual semantics implementation have been fairly consistent.

KG: Removing a bunch of stuff is still a change.

RBN: So, I apologize for derailing, we were talking about the time box.

BT: Yeah, I think the easiest thing to do, if there are no objections is to extend this item until lunch. That is a very long extension for this time box, though. So you know, if anyone has concerns that you know let me know. the will still fit everything in today. So that that wouldn't run us into tomorrow. And we'll still have a little bit of extra room for other agenda items if they need more time. so, if there are no concerns, then I think we can let this run until lunch.

DE: I'm happy to keep discussing this. I think it's an important discussion but I feel like things got a little bit heated, maybe we should take a break and go to other topics and come back to this one at the end. the end.

BT: Yeah, we could go to one of the 30 minute items.

DE: …

BT: I think the context switch would be detrimental at this point. Let's just keep it, keep it. you know. Keep. it cool and see if we can finish this before lunch. But thank you, DE For the suggestion… All right. we're going to continue this. discussion until lunch.

RBN: I am. concerned that my perception of the using declaration and what I intended for it is not as restrictive as I believe that Kevin is requesting. and I have concerns about Enforcing that I've been mentioned in this slide. I understand the concern about use after free. which is why? again the things that you should be Avoiding I mentioned you still need to make sure your object defends against because it can be used without using there. there are already user that using most of these objects that are already exists at might use this capability. Already defend against these features are these capabilities and I think there are valid use cases For. accessing these objects after dispose has been called. So, I'm leaning more towards not having it, especially considering SYG’s concerns about tdz. We have for years in committee lamented tdz and every time there's been a topic that someone said we could introduce a new tdz for this such as came up with decorators and everything else there's been significant pushback so I've been very wary about introducing something that Looks like a new tdz so I'm not sure how we're this concern Falls. in a realm of continue of, will this Advance or will this be blocked? So, I'm not sure how strong this concern is from KG and how strong the concerned against it is from SYG.

KG: I don't want to say that I will block this proposal forever if it does not have a tdz, but I am not yet convinced that it is a good idea to do this without a tdz, so I would like to discuss it some more before advancing. Anyway, there's bunch of other stuff to discuss.

RB: Would you be comfortable with us continuing this after we get to some of the other queue items because if we reach the end of the time box on this item, and as a result and there may be other reasons why this may not be able to advance today. But if this is resolved it not advancing. Then we'll probably have to move this discussion to continue it on the issue tracker. Anyways, so it might be worthwhile to continue but some of the other topics first

MF: So all of the points you list here in opposition to this binding entering TDZ discuss the object reference, they do not discuss the binding and TDZ is only about the binding. So I'm convinced by your arguments about reuse of an object after it's been disposed. But I would like to see, if we do not introduce TDZ, I would like to see arguments for you using a binding after it has been disposed.

RBN: the the main argument that I had there That shows on the slide is that the only way to still be able to Leverage the object reference that is associated with the binding would be to Alias at using a constant variable afterwards and that's not not very discoverable. it's not obvious. You'd have to have documentation somewhere that says, hey, if you need to be able to reference This. after the fact, you need to capture the binding in something else. So it just feels kind of an awkward workaround to address. the binding going out of scope. and, it might be something that I'd be more comfortable with if I had we're not postponing the `using void`. approach as a way to capture The Binding up front and then just say, okay, now I just want to track it at the end of the block but that's something that I'm trying to postpone to reduce scope on the proposal so that it has a better likelihood of advancing.

MAH: Would you be able to go back to the for-of loops slide, please? So given that the Symbol.dispose is part of this proposal. and I believe that for awaits, weights using should try to use the async disposed symbol and have the async disposal Behavior. I think it's a No. doing so, would open the issue of breaking change with which we cannot have in the future. If in the future you want to introduce `async using`, you wouldn't be able to switch to look up The symbol, asyncDispose. In this case, And by allowing dispose in for-awaits using of Of. you actually do open a lot more use cases with a seemed disposed in the async Disposable stack. so to speak to that for a moment.

RBN: One of the things that's part of what was postponed when we were talking about the what was previously, a using, await declaration, was that if you had a for-await, await that had an async disposable, you for-await because you're talking about two different things. When you're doing a for-await, you are your the awaits is in relation to the thing. You are iterating over the expression, the value that you get back, you don't also. mean, you potentially awaited as part of the iteration, but we don't do any type of among other implicit awaits, we don't start implicitly awaiting a yield star. But, once you get that value, we don't do anything with it. And I would be wary about introducing an implicit await at the end of the block, that is not in relation to the Declaration itself. which is again, so this was something that was in the proposal. the original for await x of expr, did not await async disposables. That required a separate declaration to be used

MAH: There isn’t really implicit awaits at the beginning and end, but it effectively also happens at the end of any for-await, block. I don't think it would be surprising to await the disposal.

RBN: Yeah, the only thing that would be surprising would be awaiting an async dispose here but not having a mechanism to do that for any other `using` declaration.

MAH: Right. Because there isn't any other there isn't any await blocks. in the language. This is the only one that exists today

RBN: I am not comfortable with doing that today. and to I think DE’s point about potentially, postponing async disposed. I will look it's necessary for consensus for the MVP. I'd prefer to have it as A. as a mechanism to have some way of working with a sync disposables in the short term. But if that's something that needs to be postponed until we have a better story for the syntactic using declarations with async disposables, I will be happy to postpone that which means we could defer that discussion until that proposal follow-on comes up.

MAH: It Definitely would be a bummer to have to drop all async disposal from this proposal. I mean, in general, like we're very happy with the changes you did. it would be sad to have to drop async support. I would. like to say, let's consider if using async disposal in the, for await is not something we could get away with and it wouldn't work.

RBN: I, think the alternatives are dropping using from the for Loops, which I think is unfortunate because we have had numerous discussions about dealing with receiving a receiving disposables, enduring iteration that that's, it's a common foot gun as well. So I felt that this was valuable, but if it's necessary for us to achieve consensus and, still support the async scenarios, I can go either way. But in general, I primarily preferred leaving the async functionality in as an at the bare minimum as a mechanism for async disposables even if they don't have the syntactic support, so, I'm definitely not comfortable with the for-await using async dispose. as I intended that to be something available via a different syntactic feature.

DE: Yes. yeah, so was a little bit skeptical of including async disposal. It definitely seems important to something like if disposal is used for transaction commits to have a way of blocking on that. I strongly agree with what RBN was saying about how if we do have async disposal, it should be called out with a separate syntax. so I don't agree with what MAH was saying about how you know that to just be implicitly used in a for weight of Luke? but, where it starts to get fuzzy for me about how you want to use async disposal is something like in async disposal stack. It's not just that you want to wait on the disposal happening overall but that you want to queue them up to run for the disposals to run in FIFO order and for one not to launch until the next one runs. And the other part is sort of the web platform integration side which I have another queue item about. So for me, this is not a this is not a blocking concern, I would be happy to see this move forward without making changes to whether or not async disposal is there. But I would kind of prefer to wait on it slightly. I guess I would be interested to learn more about why both the Champions and other people in committee find it important to include this feature.

JWK: Before RBN's explanation I thought that it should use Symbol.asyncDispose, but now I think we should split them. I'm okay with the status quo, await for the `using await` in the future.

KG: A very minor point: the use method on the DisposableStack has this overload where if you pass it something with a `Symbol.dispose` method it uses that, or if you pass it a function that does not have a `Symbol.dispose` method it calls the function. I would be happier if those were different methods rather than overloading the method in this way. It's not - I'm mostly worried about it actually with the second form. The resource on this case. It seems like it's doing like, kind of a weirdly different thing than the using the resource case. and like is reminds me of the second argument for the `map` etc functions, that no one ever uses now, because you just create a closure. This just seems like a weird API to me, personally. Not something I would want to fight about if other people feel strongly that it should be this way. Just not really a fan of this overload. Fan of the functionality, just not the overload.

RBN: I will say that python’s ExitStack has these capabilities, but it does use different methods for different method names for them. The approach that I took with the kind of combining the use felt, it was at the very least, the use of a disposable resource and the use of a non-disposable resource with a dispose callback seemed fairly consistent. The accepting a callback in the single argument case is more of a simplification of calling useResource on disposed where the resources no but you still pass a function. so that still registers the disposed call back because you have an explicit disposal method to execute So one option It would be. to say you have, use null, callback using the second overload. but the downside of that is that it then. adds. what seems to be unnecessarily extra work to just register functions to call later similar to Go’s defer. which is one of the things I also want to be able to leverage here. I could just add a method called defer to DisposableStack which just accepts a callback and remove the Overload on the of the first single argument case. the second case of using a non-disposable resource with an explicit callback is very important for adapting. APIs that have not implemented dispose yet. as well as objects that might not ever implement dispose because you have a very because you have a case where you still need to execute. logic when the objects disposed. So I do think it's very valuable, whether we rename it or not. not. just, for that interrupts capability

KG: For the second case, why would you not just do like `defer(()=>onDispose(resouce))`. like, the normal way that you create closures for this kind of thing?

RBN: So it's a matter of utility. if I go to this example here, you see where it says res 1 equals stack. Use get a resource one of the values of this is that if you had multiple, resources, so you say, `res1, res2, res3`. three that you can inject these stack use as expression anywhere. but, if you need to do that with a resource that needs to be tracked for disposal in or in the correct order with the correct timing. but that resource does not support. dispose, you have to do then. Do that in two steps which means you can't easily inject the use into existing code. or arguments in an argument list or anything else. which reduces its utility. and as far as so, it's not as useful for the intro.

KG: That makes sense.

RBN: That's why I'm primarily inclined because again use whatever you pass in gets returned. So the resource that's passed in is the return value and it's very useful for that interrupts case because can just inject it as any expression.

KG: Okay. I am now convinced by the second overload. The overload where you pass a callable as the first argument I am still not in favor of, and would be happier with either just do `(null, thing)` or have a separate defer method.

RBN: perfectly fine with setting a separate method to support that I think having that without having to pass a null would be valuable kind of like having the catch method when you could just use a ??? null callback.

WH: What I find confusing is, if the resource is a disposable callback and you use the two-argument `use` method, what does it do?

RBN: It would call the onDisposed callback. You're essentially explicitly registering the method to use to dispose rather than whatever's on the resource. So, in these sick in the second case, where you pass a so, Source and call back. We don't look for disposed method on the resource at all. all.

WH: In that case it should have a different name. And I agree with the previous point that having it take either a non-disposable callback or something that's disposable is just a weird overload. It's very confusing. I'm not against having such functionality, but it should use different method names.

RBN: Thank you for that information.

SYG: I think the previous discussion items adequately addressed my question as well.

RBN: Yeah. I will say that the main reason why I'd be concerned with introducing an object literal is the interop case. But I do think having a method that simplifies this is fine.

SYG: Yeah, for what it's worth I was also I had missed that and your motivation convinced me that it's fine but yes having a different name would be helpful.

JHD: I had misunderstood SYG’s queue item, but that the feedback I have is still applicable. So it kind of seems like the stack classes themselves are something that could be separable and isn't strictly necessary for the base proposal… it's definitely unergonomic to make an object literal that defines a `Symbol.dispose` method. That then calls all of the just, you know, just the dispose methods of the things that you want. want but You. can just do that and type it out. And so like this class is sort of a convenience abstraction and I'm not sure if it's - like it seems like it might be nice to wait until there's usage of the disposable protocol in the ecosystem before we… And then we can see how it's used and then we can say whether this abstraction or something different would be the most convenient thing.

RBN: So to address that I feel that this abstraction is the most convenient thing and that's from looking at the ecosystem. If you look at, for example, vs code as a repository with a large number of lines of code. And over 500 examples of their own disposable container. So having a disposable container on its own is invaluable, it's used significantly. In addition there are hundreds and hundreds of extensions for vs code That use a essentially a wrapper for the same disposable container that is provided to these extensions. And that's also used quite a bit within that code. So there is already a lot of existing examples that inform this but they use an API that isn't necessarily Global. So the VScode's dispose isn't the same thing that you would use everywhere else. So it makes composing resources from other, come from other sources more difficult because they don't - you'd have to adapt it and it does have adaptive capabilities. So the example of Back. is used, it takes based on the fact that you can create examples in VSCode fairly simply that can wrap existing callbacks. So a lot of this based on real-world use cases in JavaScript today. the API design around DisposableStack strongly mirrors the python ExitStack, which has a number of reasons for its design. And it does make things extremely convenient. I think one of the things that I have lamented in C# that has using and has the syntactic support Is that there really isn't the same kind of disposable container that exists today. And I've been considering actually reaching out to the C# and dotnet team to start looking into an implementation in the .net language of this because it is so useful. So I do think it's valuable. even if it does seem separable from the proposal proposal, Proposal proposal, I would be very, uncomfortable with not including it purely because of the fact that the Constructor case is very common and it's extremely valuable to be able to support that.

JHD: Okay, Yeah. So I mean the vs code, ecosystem example, I'm not really motivated or convinced by a VScode itself, but that the plugins use this pattern, that that is a completely valid to me. ecosystem example. and, I agree with all the previous feedback about the method names here. But I do also note that this class isn't chainable. so you kind of have to use it in a like a statement sense.

RBN: Well, you can use it in Expressions but it is not chainable for a reason. and there were discussions about one of the earlier API designs had a static `from` method that could take in an iterable or a series of arguments but that Becomes. actually a source of bugs because if you could say, I want to just take in like five. disposables and I pass them in as an array. If one of those throws then you don't dispose The ones that came before it because they weren't added yet. So there is a very explicit. There's a very explicit terseness and very explicit limitations on the API design to make sure that you're using it correctly. That we don't again. try to add multiple resources but we don't track one because we threw in the wrong place. So it is very much designed to work in tandem with `using` so that - if I go to the PluginHost example, so that you can track the entire stack using the `using` statements but then you can use this `use` method in expression cases to keep track of resources that you can. say, stack dot, use commas, stack.use comma stack that used in an argument list or in a variable list. So there's a lot of non-statement use cases, but it is designed to dovetail with the `using` declaration.

JHD: I’ve got to think more about that. Thank you.

MAH: I want to say, I'm very much in favor of the classes. I would actually say the opposite if I had to choose between syntax and the classes, I would actually want the classes. In my mind, they explain what the using syntax is doing under the hood. In my mind in a block, it implicitly create a stack and every `using` statement is basically the equivalent of a `use` call and an explicit call to the dispose of the stack at the end of the block. Having gone through the exercise, It's also really, really hard to get right in userland and do it properly with all the as you say error handling that are necessary with this kind of proposal. So I very much would like to see these classes go in.

RBN: Thank you.

WH: Okay. Looking at the slide you have presented now this seems rather unsafe if anything happens after the stack.move(), but before you get to register the result of the constructor in a `using` statement, for example, if somebody were to subclass `PluginHost`.

RBN: I do understand what you mean about the subclassing that it is still a concern. The Disposable sack does help with this specific block scope. If you were to subclass, this, and you have a super call and then throw something and then fail to handle that. the disposed as a result. There. They're you do need to have some boilerplate, that does a try-finally, or potentially adds the `this` reference that you get from Super to a new DisposableStack. can't exactly write this out. But you could basically say, `using stack = new DisposableStack; stack.use(super())` so that you're definitely going to call the dispose. and then do a stacked up move at the end when you're done so that you can not dispose your class that you just created the downside being that, that would call the indisposed. that if you have for some reason over overridden disposed with something else, you could be in a bad state. but - even if that isn't exactly supported or there is no easy way to do that. that. This still adds a lot more convenience over this, I will state that in the in C# case when you have, when you subclass dispose, there is a recommended pattern for that, which is to have a separate method that you call into to overload dispose. So that the normal disposed has a direct - has a single invocation. so there are possible recommendations that can be made on the best patterns to deal with subclassing. but I'd still rather have this than nothing at all.

WH: I don't necessarily disagree. I just don't understand how you're supposed to implement subclassing with this. That could be addressed by adding an example as you revise the proposal.

RBN: I can definitely put together an example that shows what I just described with super.

DLM: I'm not comfortable with this advancing right now. On a personal level, I think I would like to see more discussion about the issue that came up on the queue about TDZ and async before this goes to stage three. From SpiderMonkey’s point of view, in general, we still have some reservations about whether this use case justifies adding new syntax to the language. This has been something that's been raised before, YSV brought it up in October 2021 as well. And so I think we'd also as a team need to be convinced that this does in fact actually justify new syntax.

RBN: Yeah, I would like to say I originally intended to request advancement to stage three, but I was still waiting on feedback from my reviewers and editors and the editors which I've gotten some in but I don't don't think I'm at this point comfortable with advancing it any case. And I do want agree that we need to get a resolution on tdz and whether or not to defer async, I still strongly believe that syntax is warranted here. I put some information up on the explainer about Why… there's been discussions about whether or not you can just use for-of? because you can emulate this Behavior with for-of somewhat but it's still very awkward to do But if that's just because iterators have a return that kind of has similar semantics, but I'm very strongly against trying to reuse for-of for this for a number of reasons. I do strongly feel that a declaration form, that allows you to very easily declare these will be extremely valuable for a number of cases. I've put some other examples in the explainer today about working with synchronization Primitives, when working with worker threads and some of the work that we're doing. for shared structs, or fixed-shape objects to work with multiple threads and some potential that exists for working with mutexes and condition variables, which are things that we’re considering in that proposal, So I think there's quite a bit of value there. And having a very simple form that makes this very easy to use for users makes sense. We didn't need to have for-of, we implemented it for convenience. I feel like this also is a very convenient capability to introduce that helps resolve a number of common foot guns. I am still strongly in favor of a syntactic mechanism for this and I hope I can find a way to convince Mozilla that this is worth including So if you have specific feedback, you could raise it on the issue tracker.

DLM: Yeah for sure. The SpiderMonkey team went over this about a week ago, so if there's new justifications, we haven’t had a chance to review those yet and I'd be happy to bring those back to the team and try to get some specific issues raised.

and I suggest GitHub as a venue for further discussion, Or. of course, that's right. I do have one question. I need to ask to the committee quickly before we end one was that even if we're not able to stage 3 today, I am. interested in breaking off the using void. and using wait. portion portions of this proposal. I definitely do not want to abandon them and my question to committee is just as we did for The Decorator metadata. These Capability, the bindingless using and async using have been part of this proposal since its Inception. And I'd like to, as I look into branching these off in to follow on proposals the potential of maintaining stage 2 for these based on the existing discussions that we've had. And I'd like to see if I can get consensus on maintaining stage 2 for these features as they get broken off into separate proposals.

DE: I'm not convinced we want to eventually do `using void` for one. I want to suggest that we don't ask for reaffirming consensus for these things today.

RBN: Are you suggesting I essentially leave them in stage 2 just leave them as part of the proposal? My concern is that I have advocated for binding was using since day one, I think it's an invaluable and I don't want to abandon it. And I hate to have to even if it may be necessary but I would rather not try at have to re push this through stage one and get to Stage 2 again on discussions that we've already had.

DE: Yeah, I think finding list forms were useful in general. and I don't think it so tied to using, I mean it, worked out naturally with earlier versions of the proposal, but it is, plain, this is kind of more like an underscore future. I think void is a pretty awkward way to do it because void is an operator normally so I'm not I'm not in favor of state 2 for broken off using void proposal. I haven't seen enough justification for that.

RBN: Do you have any concerns with breaking off `using await`? or the old `using` statement Declaration to separate the two?

DE: I would like to see a presentation that goes into more detail on asynchronous using stuff. So I think I think we can say that if we're leaving this proposal at stage 2, and these two things are both part of the problem space, and then when you're able to give a dedicated description and presentation of what it is that you want to keep at stage 2 and why? then that would be good to ask for consensus on that way.

RBN: I did hope to discuss those earlier on, but cut some of the slides short given time. That's fine. I will leave - essentially I will consider these to still be part of the stage 2 proposal. And when at the next meeting will seek to eventually break if we can advance, if we reach a point where you can advance to stage three and break these out, I'll try to make sure that I have specific separate presentation for each of these features, we can discuss them in isolation.

DE: Yeah. that sounds good to me.

### Conclusion/Resolution

- Proposal is not advancing at this time. DLM to discuss more with Mozilla, other people to continue discussion on GitHub.

## Extractor Objects

Presenter: Ron Buckton (RBN)

- [proposal](https://github.com/rbuckton/proposal-extractors)
- [slides](https://1drv.ms/p/s!AjgWTO11Fk-TkoEtBecgCeh0FRhDqw?e=6ahvlJ)

RBN: For hopefully no more than the next hour, I'll be talking about. something called extractor objects. I'll go into a little bit about the motivations behind this and what I'm looking to accomplish, but first, I want to give a brief introduction to what an extractor object is. For anyone who's not familiar, extractor objects are a feature of the Scala programming language. an extractor object is. essentially an object that has an unApply method. Scala uses this prodigiously within variable declarations and pattern matching to. essentially extract the arguments that were used to produce a result. to provide a little bit more context, in Scala. An object can have an apply method and that's kind of, like, a Constructor, or a function. the apply method accepts arguments and it produces a result. This is not unlike function apply, or creating a new object via the new keyword in JavaScript, you pass in arguments. you get a result either an object or value. So essentially, the unapply method is the inverse of apply, it accepts a result and tries to give the arguments. So the example here, shows a customer ID that on application takes in a name and A random. ID and un-application takes in a formatted ID. And if it matches successfully Returns the results, otherwise it returns a value indicating that failed to match. So you can see here, a value of customer ID is created by applying customerID to a string, and you can then extract the name. then by unapplying the customerID. function, or the customer ID object to the results. Providing this interesting inversion of a call

RBN: How were these extractors used? Well? Scala uses extractors and variable variable declarations You can call unapply on the provided on the object, that's referenced using the argument. That's assigned from the right. If that matches, the result is then destructured to whatever variables are used. In he example of customerID, you would take this string. parse it, and if it is valid it would extract the name from the beginning part. similarly, if you had a point object that you could construct an X and Y value, you could extract the original X and Y value by taking the point on the right hand side the assignment and passing it into the left hand side. And then unapply is a unary functions gets called and then produces a value that in this case is a list that has a first and second argument.

RBN: One thing that's important about this is that extractor objects are exhaustive, which means that for a value to be extracted, it has to match successfully. If it does not match, then it throws an exception. So if you tried to extract a value from a Some but provided a None, this would be an error. This is also used with, in Scala, with pattern matching in a Scala match. You can provide multiple cases and you can then match on the an extractor pattern to pull the name out to be used on the right hand side. matching a shape or a point you would match the X&Y, for a rectangle you might match the individual points, or if you're matching an option you can. match on whether it was a Some with a value or a None. Similar to variable declarations. to variable declarations. You use the same matching behavior but in this case, if a match fails, it'll move on to the next alternative in the list, Next, extractor objects in Scala, have a lot of similarity with languages both roughly in syntax. And sometimes, even an implementation. Rust's pattern matching uses a, if not user-defined mechanism, a similar approach in syntax to extracting objects. F# has active patterns, which lived you defined functions that can be used in a pattern to provide the same type of extraction. C# has the deconstruct method, which allows you to take an object and extract it into what is essentially a tuple that can then be used in pattern matching. The Hax language supports this through algebraic data type based enums and pattern matching. And there are some additional similarities in languages like, OCaml, racket, Swift. And a number of lisp derivatives.

RBN: So, how would extractor objects relate to various currents and past and upcoming TC39 proposals for ecmascript? There have been past proposals that have discussed similar syntax that either didn't Advance or were considered, but then not proposed, proposed, There. was a previous extension extensible collection, literals proposal that provided a hook or symbol based API. mechanism for doing this. There was a collection literals proposal. That was originally discussed by Kat Marchan as part of around the same time that pattern matching was introduced. There's currently a pattern matching proposal that has very similar (?) to this and could potentially leverage this and upcoming such as enums and potentially algebraic data types.

RBN: So I was talking about the past proposals. One example here was from Kat Marchan about collection literals, the idea being to introduce a novel syntax that allowed you to construct a Map or a Set or essentially, any value using some input value on the righthand side and then support it in both the structuring and pattern matching. Current proposals. We have the current pattern matching proposal, which uses a novel Syntax for matching values that be a patterns and has some support with custom matchers that provide user defined matching behavior. In this example, basic patterns are supported such as matching object literals, matching what is essentially array destructuring, matching literal values. and the ability to use custom matchers using interpolation syntax and the `with` keyword.

RBN: In upcoming proposals, this was previously discussed. in a plenary last year, it did not advance, I think there is some additional changes that we will be making to the proposal, but I think there is still significant value to enums and algebraic data types. I know I and I'm sure the Jack Works, who is one of the champions for this, intends to bring this back to committee. in the future. future. I think Specifically algebraic data types of a lot of value that can be added to the language. Both providing structured values, providing something that is record-like in its implementation that could potentially be supported over in shared code contexts with fixed sized objects. There's a lot of potential for algebraic data types that could be leveraged.

RBN: So, with that brief tour of what extractors are, I’d like to now, actually, go into kind of what some of the motivations are I have for bringing this to committee and some directions that I think we could potentially take if we're interested in pursuing this. Currently there is no mechanism to execute user-defined logic during destructuring and despite the cases that I showed around, algebraic data types and pattern matching, That. is one of the more interesting cases that I interest that I'm looking to investigate. Currently with destructuring You can wrap the value that you are going to destructure in a function call. If you need to do some type of validation or normalization, but once you get one level deep within destructuring, you cannot then execute any other code that might affect destructuring. You can't validate incoming parameters, or parts of an object destructuring that you might want to check before moving on to other properties. And then up having to split things out into multiple statements. So there's some interesting values that can be achieved by enabling user-definedd logic. In addition. pattern matching does provide or propose a way to execute user-defined logic during matching with custom matchers. So if pattern matching moves forward with custom matchers then there would be a disparity between what you can do with patterns and what you can do with destructuring, the enums proposal and specifically att's would benefit from a syntax that is consistent and convenient across declaration, considering destructuring, and pattern matching since such can see such consistency is a key to being able to learn and understand the behavior of these features. If we had inconsistent syntax for declaration and construction, for how you create them and how you read from them, that can make it more difficult to actually follow what is actually trying to be done in the code. Also such consistency is evidence of immature and coherent programming language trying to avoid introducing warts into the language because we try to solve one problem, but at the expense of other other problems, and potentially introduce new ones down the line. And we unfortunately have these. Everything from Symbol.species, the regex methods. We've sometimes have implemented features that seem valuable at first, but then can end up tripping ourselves up and down the line. And I think looking into a syntax that we could have achieve some consistency would help us to have something that's a little bit more stable in the future.

RBN: So to get to that, I'd like to talk about what extractors are. There are essentially two things that I'm discussing, potential Proposals. one is the specifically a proposal for extractors. in destructuring and I'll talk a little bit more about pattern matching in a moment. so, what I'm proposing with extractors is to investigate the potential for introducing novel syntax that allows us to execute user-defined code during destructuring. This allows inline data validation, transformation, and normalization. We could leverage the scala extractor objects and rust's variable patterns as prior art or base this design on custom matchers from pattern matching proposal. An earlier version of this had a separate symbol .apply method but I found in discussing this with the pattern matching proposal champions that I could just as easily leverage the proposed. Symbol.matcher. Built-in symbol that they're planning to use. This would also provide parity with custom matchers that are in the current pattern matching proposal will allow them to be used in destructuring and provide a basis for potential future with enums and algebraic data types.

RBN: And there are three areas where extractors can be applied: binding patterns such as variables and parameters, assignment patterns, and match patterns. There are two categories of extractor patterns array, extractors where the extraction is then evaluated using a radio structuring an object's just director is where extractions evaluated using object destructuring and, in this proposal and extractor consists of essentially two parts; a qualified name and this is another name for what is already in the decorators proposal, which is either an identifier reference, or a series of dotted identifiers, identifiers, following identify. But this would be something that references a in scope binding, that is a custom matcher. An object that has this Symbol matcher method. Array extractors, an extractor has either an array extractor pattern syntax or object Constructor pattern that follows it. So again these qualified names are then used to reference custom mattress in scope much like how decorators reference identifiers or dotted identifiers.

RBN: Array extractors with a binding pattern performer destructuring on a successful match. They are denoted by parentheses rather than square brackets helps to avoid confusion with element axis expression, computed property names and looks similar to a call expression, expression, which then allows to mirror construction versus application. So here you could parse a string input into three outputs and this parallels the same behavior we have for array destructuring. Here. you can see extracting a list of (a, b) from the creation of a list of two values. or extracting an option.Some value from a value that contains an option.Some(1). To support an essential pattern matching tenant of ensuring that patterns are exhaustive or the pattern matching is exhaustive for destructuring. We would want to error if the match fails. This is not unlike how if you try to destruture null, we will throw, or if you try to use array destructuring with an object without a symbol iterator, you would throw. This ensures that you don't end up with a garbage value in the constant that you're declaring. or The Binding that you're declaring. and avoids having to worry about introducing some type of fall back object that could be used in further destructuring. So throwing expect to find are I think is more reliable in this case. Array extractors and assignment patterns are very similar. Again. they parallel destructuring patterns, we already have where a array destructuring of A, B is paralleled by the array construction on the right list of A, B parallels. The list of 1, 2 on the right. This would require a cover grammar to support but I think is still, it is still feasible since currently a call expression. cannot be the target of an assignment. That is an error. Objects extractors are similar, in object structure and bonding pattern forms object. destructuring rather than array destructuring and uses curly brackets similar to an object literal. which means it's consistent with the existing structure and syntax and Potential. and mirrors. future role little construction. Syntax that ADT enums would hope to employ. And similar to this. The Binding patterns, object extractors in assignment patterns will use curly braces, and we would most likely enforce parentheses around these to avoid carving out too much syntax space of identifiers curly, we would want to definitely ensure that the thing that you want on the left is something that is a valid destructuring assignment target. And, as with array extractors, in both cases, these will throw errors.

RBN: The other thing I want to discuss is extractors in pattern matching. essentially, this would be a change to the pattern matching proposal and it's something I've been discussing with the champions. I am not presenting this pattern matching side of extractors as a specific proposal for stage 1 adoption today. As I see this as more of something to discuss with the pattern matching champions, but in discussions with those champions, it became clear that I needed to present a more cohesive extractors proposal to the committee before the pattern matching champions would consider this as for adoption within pattern matching itself. But that said, extractors and pattern matching would essentially _be) custom matcher that are in the current pattern matching proposal.. They would leverage the same user defined pattern matching features that you can see in scala, rust, F#, C# and many others. Again this provides a basis for potential future that includes algebraic data type based items.

RBN: Array extractors and pattern matching are again very similar to binding patterns and assignment patterns in that they are still denoted by parentheses. They still resolve the qualified name to something referenced in scope, but In. my opinion. Hopefully provide a much better syntax compared to “with”. The difference between a pattern matching extractor and a binding pattern extractor is that binding patterns definitively throw if the match fails whereas a pattern matching extractors, the correct extractor would then choose a different alternative or a different branch. in the match expression, and much like the object binding pattern or object of tractors in binding patterns and assignment patterns. They could also be potentially used in pattern matching as well.

RBN: I'll go into a couple examples of what this might look like. Here is an example of array extractors and binding patterns. An object extractor extracting the coordinates for a point, extracting the from a option from an ADT enum, the value of nested destructuring here, you can see, you might have an object that has a property that might be a Map object and you might want to then pull out the values that have the keys of bar and baz. And then further destructure that. Or nested scenarios where we might have an ADT option enum, and an ADT message, enum and we might want to extract the coordinates from a valid option. Some of a message move. and, finally, this example shows of makeRec shows, an example where we could use these same patterns on parameters to extract the coordinates from a start and end point. point. Another. example of this use case would be something like this instance is extractor. This is another example that I have in the explainer today. This shows how you could have an object that provides a specific shape. Many ORMs that exists in JavaScript today, such as type ORM or micro ORM provide a mechanism to hydrate an object by constructing it and passing in a DTO, a data transfer object as the first argument to the Constructor. that contains the values that it receives from the database. In this case, you could see how we could have a set of properties such as ISBN and title. We could then extract the created at Look at this. passed in. value. and if it is not an instance but it is convertible to an instance, we could potentially match and then convert based on the types that we supply. And then the same thing for modifiedAt. But with the value, added value that we've already done the work for createdAt. So, in this case, we would extract modifiedAt. But if it's undefined, we don't do this work. Instead use the default that would be provided by createdAt. So it allows us to skip some extra effort.

RBN: Another. interesting example would be supporting custom matchers in regular expressions and how those can be used with extractors. So here this shows if we added a Symbol.matcher method to regex prototype, that essentially returns an object when it matches successfully that has explicit keys for the key values in groups and iterator that iterates over the values, which allows us to use the same object to have the named capture groups as well as the implicit ordered captures, and then we could define simple regular expressions. such as an ISO date time that just extracts the date section of the date part in the time part, that extracts the year, month and day from the date portion and hours, minutes and seconds from the time portion. And I know this isn't 100% ISO compliant. This is very simple representation, but then you could very simply extract the portions of a date by saying, `const ISOdate{ year, month, day } = input`. So this would then reapply the string input through the regular expression pattern and extract out the year month and day and captured groups and gets even more interesting when you have nested (?), where we could take input extract out the date and time sections and then further extract out the months. days, hours, minutes, seconds, and also still use this within something like pattern matching to say that we're going to match a date-time and match the valid date and time.

RBN: Yes, I don't want to break your flow but I think there's a clarifying question from WH asking you to explain the Constructor syntax? I think two slides back.

WH: Yep.

RBN: What do you mean the Constructor syntax?

WH: What is going in the constructor parameter list on this slide? I don’t understand the novel syntax.

RBN: The constructor takes a single parameter, which is using an object assignment pattern. So this is destructuring the incoming object into a series of properties. Without extractors this might say, `ISBN, title, createdAt, modifiedAt` and then you would need to do the various work for validation and data transformation data transformation as multiple. it's within the body and have to deal with if modifiedAt is not supplied using createdAt or potentially, converting modifiedAt. This syntax allows you to have a much more condensed approach to destructuring. So instead of just destructuring to create a property, instead we are taking the createdAt property off of the argument, passing it in as an object… I think I actually need to make a change. There is a typo on this slide which is why this might be more confusing. [RBN edits slides in realtime] So in this example, what should have that should have actually said that the createdAt is then pulled into the instant extractor. So the property is pulled into the instant extractor, which receives it as the value of the matcher and then that goes through this expression that determines whether or not it is a successful match and what that match value is and then the result is turned into an array. Here you can see if it It is. instant that came in the match value is array that contains a single element of `value`, which then is destructured, as a single element containing a property named createdAt.

WH: Okay. So the first `createdAt` is now the property name of the incoming object, the second `createdAt` creates a local variable with that name?

RBN: Yes, that becomes the local binding as if you said `createdAt: createdAt` essentially.

WH: OK, thank you for correcting the slide. When I was taking a look at it earlier, I couldn't figure out what was going on in there.

RBN: That was a typo and I do show with the iso date-time showing I think a much clearer example of this with date:, ISO date-time colon time. So, that was a typo in my transcription. So, to continue. With extractors and pattern matching there is an interesting value in how succinct the expression can be. The current pattern matching proposal leverages uses an interpolation care syntax that is similar to string interpolation the dollar, curly and curly and also requires a “with” keyword and then a destructuring pattern that follows it, which becomes very cumbersome to use when working with nested patterns. I've also been talking at length with a number of my contemporaries on the TypeScript team. We think that there is a potential for a pattern matching syntax that does not require interpolation. And would become much more susinct, where you could just simply say, when `Option.Some(Point)`, and extract the values, when `Option.Some with …`. And extract the values. Or in the example of the top, when message, right, text. or when message move, X&Y and Y and it becomes much simpler and easier to read than in my opinion than the current pattern matching syntax. So I think it could provide a very viable alternative to the interpolation and with it's Syntax that's used in that proposal.

RBN: and, there's some additional considerations about extractors. So the proposed syntax is a very tentative and is subject to change during stage 1. If this is adopted. Right now, I've presented a lot of syntax but these are very early, rough ideas about what this could look like. I am aware that we might need to disambiguate being in fixed token, similar to the collection, literals proposal. We also might need to drop Objective Extractor in favor of just an Array Extractors with the inverted call like behavior, that just has an object literal, But I'm concerned that might break symmetry but it's something I'm willing to investigate. And I also want to make sure that we're again able to do something that could be consistent with a future algebraic data type based enum proposal, which we do intend to propose in the future. But extractors provide more value than just what you would get out of ADTs even if we choose to pursue them. So I'm very much interested in pursuing this with or without,ADTs. But if we do choose to pursue ADTs, one of the things again that I mentioned I am interested in is a way to achieve consistency between declaration, construction, and destructuring, While this hasn't been adopted by TC39, there's been some interest. So, I'll show example of what I mean. Here we can see an example of an ADT enum that defines a right entry that contains essentially, a tuple of potential values. The name here isn't actually important except for potentially debugging or toString representation like cases. since the ordering is what matters. Itt's also very informative at least. Here we also have a `Message.Move` enum member that is a record-like value you a tagged record like value that contains an and Y property. its construction might look like message dot, right. With a string, which is just a normal function call, message.move with curly braces which would be essentially the tagged record construction call and destructuring would then look like that.

RBN: so, that leads to kind of my summary and open to the queue. I am seeking stage 1 to investigate the potential of introducing extractors in binding and assignment patterns. I am not seeking adoption at this time for extractors and pattern matching as that something I plan to continue discussing with the pattern matching champions. and will likely hinge on the potential advancement of this proposal is I'd like to make sure that all of these syntaxes are consistent.

RPR: All right and thank you for that Ron. We should go to the queue.

WH: In the examples so far object destructuring binds the same variable name as the field name. Are those required to be the same or can you rename?

RBN: You can rename. It's essentially allowing you to execute code in between, reading in the value that you will bind into it. And the thing that you actually, further, bind or destructure so you can change createdAt to be whatever you want. but those both use already structure. and your knees are using array structuring. Yes. So the value name you're providing in the instant extractor is whatever you chose to name the variable.

WH: I was asking about object destructuring. In this example you have array destructuring. In object destructuring there is a field name and a bound variable name. Do those two need to be the same name?

RBN: No.

WH: How do you specify both? There is only one identifier in the examples I’ve seen so far.

RBN: Here's the example that I've underlined here, I'm just destructuring an object literal. I'm just destructuring the foo property. So I have named the property into a further destruction thing. So I could imagine in JavaScript today, if you just remove the map identifier here, where your destructuring Foo into a nested object literal that then further destructures bar and baz, and baz further destructures into another property name. This would introduce a binding for bar and a binding for flux because those are the findings that you've declared. In the case of an extractor object, you're introducing a function. or an object map that has a symbol dot matcher method. So the property the value would read from. the foo property is then passed into the symbol matcher method as the value that then returns, something that says it either matched or didn't. And if it matched what you are, then further destructuring. So it allows you to inject some user-defined code in between reading the value from the property, and then doing the further destructuring that allows you to again do validation data transformation.

WH: So the simple answer to my question is the syntax would be `baz: identifier`.

RBN: I'm not clear on what you mean there.

WH: The question I was asking is, when doing this kind of destructuring how do you assign to a different variable from what the field name is?

RBN: Yes, you would just say `baz:` because once you have gotten past the extractor object syntax. that prefixes. This you're then just looking at a normal object destructuring so So everything from the curly following map to the matching curly at the end is just a regular object destructuring and follows that same syntax and evaluation.

WH: Okay.

WH: The other point I have is, this thing is making use of the syntax of an identifier followed by `{` and that may clash with other proposals which try to use that inside expressions.

RBN: I'm aware that's a potential concern I mentioned that here we might need to have to disambiguate via an infix token, the collection literals proposal use a `!` character. Another potential would be using a hash character since my intent with ADT enums is that those might be essentially a tagged Tuple. it's tagged with the member named in some way and a (?). So there's potential for something, that or some other infix syntax. And I also mentioned earlier that when it comes to object extractors in assignment patterns, we might need to prefix with parentheses so that we're not stepping on all of the identifier curly syntax space. There's still potential that you might want to have a keyword curly on the right hand side. but that wouldn't necessarily affect the assignment on the left hand side since that's already a restricted. We already have a covered grammar and it already has a number of restrictions to what's actually allowed which is one of the reasons we could potentially do called the, the a call, like expression on the left. So there is potential for conflict and it's something that I want to further investigate and explore. should be Advanced to stage 1.

WH: Okay.

KG: I am generally in support of something like this. In particular, one of my biggest concerns about pattern matching is the sheer amount of stuff that it introduces that it's just for pattern matching. So if there is a way that we could rip off this portion of pattern matching and make it not just for pattern matching, I would be in favor of that, whether or not pattern matching advanced I suppose. I do want to say, I don't want this if it is not what pattern matching is using. I don't think we can reasonably have both, but if we can have this and it can be used in pattern matching or if for whatever reason, pattern matching doesn't happen, this still seems nice. So I'm in favor of certainly going to stage 1 and exploring this.

RBN: Yeah, I definitely agree. I'm very much. Interested in this for pattern matching. And from my discussions with the pattern matching Champions, it definitely feels like a bit of a chicken and egg thing. It's less likely I'll be able to introduce this in pattern matching without a stage one proposal to investigate this for new structuring or just as in general. But I definitely don't want to end up in a situation where we do one thing for pattern matching and something completely different for destructuring. This whole proposal about looking for something that allows us to achieve consistency and syntax and introduce some capabilities, that will be invaluable for algebraic data types in the future, which will heavily utilize both pattern matching and destructuring. So, I think it is extremely valuable for both. I also have - I kind of have a vision for what I'd like to see pattern matching do. It's something that I've been discussing at length with the pattern matching Champions and this is one of the key pieces to that discussion which is why I bringing it to committee?

She? has a clarifying question. Question.

SYG: Kevin, do I understand your position correctly that you are asking that you'll be happy with this going forward. If pattern matching hampions also reduce scope in that proposal, Because my understanding right now is this Not. in place of stuff in pattern matching, but can compose with stuff Strictly. and pattern matching and additive

KG: It's not strictly additive to what's in pattern matching. There is something that is in pattern matching that is a lot like this. And if the thing that is currently in pattern matching goes to stage 3, I would not want this proposal to further advance unless it was able to use. literally that syntax, which I don't think it would be able to do. I'm not asking that pattern matching be reduced in scope per se, just that if the feature of Ron is proposing goes forward and pattern matching goes forward then the future Ron is proposing must be a subset of pattern matching - or not a subset of pattern matching, but like the thing that is currently in pattern matching must be the same thing as what Ron is proposing.

SYG: And the current the thing that is currently in pattern matching is this `with` thing that's on the screen.

RBN: Yes. It's my hope that this syntax is much more readable and concise and easier to reason over and I am hoping that is convincing enough of a reason to consider its in place of the current. currently proposed with syntax. And interpolation. I don't find the interpolation syntax to be valuable and I think that there are things that we can do that to make it completely unnecessary. So I feel that this would be a more than adequate replacement for that for both the use of interpolation and the with keyword here.

RPR: Okay. SYG, are you happy?

SYG: Yes. that clarifies.

RPR: It sounds like they are both fine on their own, but it's the intersection of both proposals where there's some coordination needed.

KG: Yes.

JHD: I just want to talk about - pattern matching has tried very hard to match destructuring and only deviate from it where it's highly intuitive and relates heavily to patterns. So if this feature existed in destructuring, then pattern matching would have to account for it and support it. And, then the other point I'll make is that the use cases for the `with` syntax are not completely covered by what I believe has been presented here as a possible solution so further coordination would certainly be required because I agree that we don't want both of these things advancing such that their syntax doesn't heavily overlap. Yeah.

RPR: Okay. Hearing lots of support for the coordination.

WH: My position is a bit stronger than that in that I don't want pattern matching to just expand to cover the new extractors. I would want there to be just one such extractor syntax in pattern matching — I would not want pattern matching to include both this extractor syntax and the `with` extractor syntax.

RBN: I agree with Jordan's comment, that we’llneed to coordinate on the cases where `with` doesn't work. I think the the one case that I can think of that, this doesn't cover be the I want the matched value, not to further destructure, that's something I've been considering as well.

DE: I agree with everyone saying that there has to be a common syntax here. Jordan, I didn't really understand the case where you can use `with` that you can't use this, I guess Ron was just mentioning this. Could either of you explain further what that Gap is?

RBN: I can speak to that if that's alright the extractor syntax currently depends on further destructuring either into an array, or into an object literal. whereas the current “with” syntax would allow you to use a custom matcher on the left, say with, a binding on the right that because the thing on the right is another pattern. The current extractor syntax doesn't support this. The way that this is supported in Scala, is they have very specific semantics that if you return a Some that contains a non tuple value, that is the result. So, you can you still use parentheses but you just get that one value. and, if you return a Some containing a tuple, then you get multiple values. Because we do not have a option.Some capability in the language today and although there have been some discussion earlier examples of how you could possibly implement this today with custom matters and pattern matching, I'd be reticent to do so in the language itself until we've actually thought. more about algebraic data types and how they should be representative so we have something consistent. But I do think that there's also an opportunity to investigate a specific mechanism for doing a custom match into a value. One thing I've considered was saying `option.Some space identifier` and then that be it. I don't know that I would necessarily be. 100% supportive of that in structuring, but again, this is an area that I think we need to further discuss.Jordan you're welcome to add it If you think that is anything that I missed.

JHD: No, I mean, I think that's good. I haven't read through. the extractors proposal enough to be able to have a concrete list of overlaps, but there's a number of places including the stuff around its mentioned where it doesn't 100% match up. We may decide that's okay to not serve the additional use cases, but yeah the pattern matching proposal has more discussion to be had before coming back for stage 2 anyway. So Ron has been, and will be part of those discussions as it relates to extractors. So I think that we'll have to be able to make a good case for that later and we probably shouldn't spend time doing that right now.

DE: Okay. We all agree that there's more discussion needed, What I don't understand is - I mean, it sounds like we're just talking about talking about differences in The. match protocol not, it doesn't really and how expressive they are. But just in the form of the protocol itself, because,

JHD: It's not about the protocol, it's about the ability to chain and compose patterns and the extractor syntax seems to be limited in the ways you can do that, the pattern matching syntax is not limited intentionally.

DE: Do extractors not allow nesting? Or like, what is the composition that pattern matching allows?

JHD: This is where I'm having difficulty coming up with an answer on the spot.

DE: Yeah, suffice it to say that I don't understand the difference yet.

RPR: Yeah, everyone's agreed that there will be further discussion. So I think this is good to advance to the next topic.

ACE: Yes. So further just echoing what people have said, full-on positive this going forward. I like the syntax like maybe with some tweaks but generally it looks good. Before someone else says it, it this also seems like with pattern matching, this proposal, the ADT / enums proposal, there's that kind of implicit Epic happening of, I kind of want each of them, if all of them happen, but also want each of them to be explored separately and to kind of stand on their own as much as they can. And I think that's a healthy way. Maybe in the future, they get merged together. So they land together. I don't know. I think that maybe the I like the fact there's multiple proposals that will complement each other, but feel like exploring this separately. so it's can be kind of ensured that it kind of works as well as it can without, say, for example, with pattern matching the risk there is because pattern matching creates its own syntax scope it could almost create any new syntax it wanted, whereas exploring this separately forces that it to be more compatible with the rest of the language. I think that's a healthy way to explore this. Big plus 1 to stage one.

JHD: So this is certainly a stage 1 concern and not a stage 1 blocker. But I have a lot of concerns about the syntax. In particular, I think the `identifier{` is not what I would consider pleasant, and I don't think dropping the object extractor functionality is actually viable. So I think there's a lot of syntax exploration that will need to be done. so that's just brought up as assuming. that this advances to stage one as a heads up, that's something to explore in stage 1.

BSH: Yeah, my main concern here is, I feel like this feature is creating a way to write code that's very terse and clever but not necessarily easier to get right or easier to understand. In several of the examples, it looks to me like, you'd have to - to really know what's going on you would have to go and read what the extractor code does to understand. Well, what things can I use this extractor with? And what can I put on the right hand side? I don't see the benefit to balance out the readability. or what, wait, what does this in some way? Let you write more efficient code easily. or does it somehow - aside from the magical feeling and cleverness, what's the benefit?

RBN: Well. for one I'd like like to say that there's significant benefit when it comes to pattern matching, there is a lot of evidence for this syntax in a number of very popular languages from C#, F#, R BSH:ust even Scala and many others have very similar constructs when it comes to what pattern matching looks like especially when dealing with complex objects. This definitely dovetails with what an algebraic data types proposal might look like as a way to express tagged records and tuples within a specific domain like we would with option having a Some and aNone. and having this, in pattern matching but not having it in destructuring would be a mistake. and the destructuring side of things is something that's still extremely valuable in heavily used in those other languages that also that have these capabilities.

BSH: I can completely see how it improves things with pattern matching. And perhaps my criticism is partly because I'm not completely convinced about pattern matching itself. So I think what would address this - Not something you can do now, but what would address my concern here, is if I could have a solid example of some code. Like, here's how you would write the code with this feature available and here's how you write it without it, and it's not just that it's shorter, but it should be actually easier to understand and maybe more performant. because, there's some benefit that you're getting performance-wise out of like the environment doing this for you. That's what I would need to see. That's all I'm saying. I'm not trying to block this or anything. I just that's that's my concern. I feel like it's just feels too clever and not really overall beneficial. That's it for me.

RBN: Well, I would say yes, it is clever. But it is also we're not again we’re not the first ones that would be using this. It's been a long-standing pattern in a number of other languages. And while it is clever it does allow you to be more terse It allows you to have shorter lines of code when it comes to code reviews, it allows you to do some complex things that you cannot do with destructuring that require multiple statements to execute. I have to check. I do believe I have an example of this on the explainer that shows the kind of the difference. I'd have to look. I think it's the instant extractor example that I showed in the earlier slide. That's the code to do this without it is multiple lines of code that there's possible repetition additional checking have to do so you're not redoing work. It does add a lot of people not having this today means more complex code that this can significantly reduce. Then having a form that if and when your team is, Our. is, proposed accepted the end advanced. having something that allows you to kind of work easily with these type of strict data structures would be. I think would be invaluable as evidenced by how commonly they're used in languages like rust.

RPR: Yes, it's the sense that it will be easy to satisfy BSH's request here to just reviewing the explainer and seeing that we've got those examples is crystal clear.

RBN: Yeah, I'm happy to go through and add additional examples.

KG: +1

MM: Okay, so first of all, I support stage 1, but I do think it's worth explaining why I'm skeptical. I think that this feature — if you're constructing a new language from scratch, this is very useful. In fact, I did something that has some similarities to elements of this in another language and it was very, very useful. I loved it. The thing that we need to remember is that millions of people learn JavaScript as their first language, and they learn it from people that we would not consider to be language people or language experts and the fact that something is pleasant and viable in Scala — Scala does not have the dynamic range of programmer expertise that JavaScript has. People often learn to program in JavaScript by looking at other people's code and making incremental modifications. We're already a very hard-to-learn language and our language is already too hard for the purpose that it serve the world if we're over our syntax budget. So, I'm very skeptical this one but I also want to say — because I'm not doing anyone any favors by not saying this — the existing pattern matching proposal with the existing syntax on the interpolation and `with` is a non-starter. I could not imagine agreeing to go to stage 2 in that form. If we were going to do that, I think what Ron is showing here is a basis for a pattern matching proposal with a much more intuitive syntax. That would be the only way that we would get to pattern matching that I could see admitting into the language. So in any case, pattern matching research at stage 1, this proposal's extractor research at stage 1… that's fine.

RPR: Thank you Mark. I think KG was agreeing.

KG: Mark, you got to what I was going to say in the second half of your comment. I agree that this simplifies pattern matching and that is a good fact about it.

RPR: Excellent. We have one less than a minute remaining.

WH: Yep, I agree with everything Mark said.

JWK: I like the round `(` form but I am skeptical on the the `{` because in a previous slide Ron mentioned about the reflective syntax that can construct something with the curly braces syntax (`const x = Map { }`), we need to preserve this syntax space for other future usage. Like pattern matching requires a match `match [No LineTerminator here] {}`, do expressions also need that `do [No LineTerminator here] {}`. If we use this kind of syntax for construction, we will waste too much syntax space.

RBN: Yeah. I again, I'm aware of that also So match Requires match, NLTH, open paren followed by an expression. A close paren and then another no line Terminator in a curly. So this doesn't step on Match. It doesn't step on doExpressions because `do` is a keyword, I do see how it could potentially step on other future identifier early in expression space. And that is again why I am still declaring this as very, very early syntax and something that I'm actively planning to investigate how whether the object patterns are Whether the option pageants are an option. I think I had on the on here. It's that, it may be necessary to drop object extractor or patterns in favor of only a regex extractor patterns. I'm worried about the possible break-in symmetry with what we'd like to see with. Hey. ADT's, and then ADT's still needs to further investigate. The proposal still needs to further investigate what that ADT construction syntax would look like. So, there's a lot of exploration needs to be done here, and the upside is that we could still potentially move forward with the array extractor capabilities and for destructuring, and continue to iterate on object extractors as we go. but at the very least to having investigate the syntax based gives us a chance to find those inconsistencies and look for alternatives for syntax?

RPR: Okay. excellent. Ron, would you like to ask for stage one?

RBN: Yes, can I have stage 1? [silence] OK, thank you.

### Conclusion/Resolution

- Stage 1

## Refactor of import-related Host Hooks

Presenter: Nicolò Ribaudo (NRO)

- [proposal](https://github.com/nicolo-ribaudo/modules-import-hooks-refactor)
- [slides](https://docs.google.com/presentation/d/1RVUE-MENQT8dj2wxvMLMDxg_VoMOwiwNQQged39QIEU/edit?usp=sharing)

NRO: Okay. Okay. so this presentation is about refactoring import related host hooks, specifically, host module and host import module dynamically. Before look in there Factor, first. Let's see how it is currently specified. This slide might be a bit complex and like, two months ago I couldn't understand what it said, so if you prefer you can check the link of my slides in the agenda and there are some hidden slides my slides in agenda at with a simplified version. version.

NRO: Oh, Okay, so what's happened? When the host wants to load the module, for example, using a script in HTML this process is necessarily split between the host. And at Mag School, so, first the host starts, loading the module and all its dependencies recursively before calling in ecma262 and I call this the graph loading phase. while doing these the host has to parse every module using a like a helper provided to in 262. like it parses the models. As you can see, and records dependencies and check if there is an error. This process is potentially asynchronously because fetching usually involves like a network call. So after this graph, loading phase which means the potential asynchronous, we have the graph linking phase and And at this time, host calls into ecma262 to method called Link, calling this method recursively, iterates over all the models in the graph and to get every model in the graph, it calls this host hook, which is called HostResolveImportedModule. This. host hook results. The reference pacifier. pair, where the specifier is the string, the to brighten import statement. So that the host can return ecma262 to the corresponding dependency, the module record of the corresponding, corresponding, the papacy After. doing all of these. So we're at no 26 to ask for each dependent City hosts. We have the evaluation phase. And linking phase is needed to check that the imported and exported than the first match. Then we'll have the evaluation phase. Again 262 to literates through the whole graph again calling cost resolving proctored module to get all the dependencies and it evaluates one by one. and this again is potentially asynchronous because There. might be top-level await. However, the asynchronous part is after interacting with the host, to get all the modules, There is a requirement. that HostResolveImportedModule must be idempotent. So if, a specific model record for a given reference specify repair, its mustard on the same model record every time. So if it's safe for 262 to call it multiple times

NRO: so, from an Ecma 262 point of view, module loading is synchronous because they are asynchronous parts that Ecma262 see is is only at the end. are while evaluating top-level away and this is synchronous because hostage of imported model synchronize, the odds from a technical point of view, the dependencies when they're needed. However, from the host perspective module loading can be asynchronous and it can return synchronously from the host hook only because it populates a cache, and it was true that this looked sync in 262 to until 2020 when we introduce dr. dynamic import. Because how does importing a module dynamically work? Well, it's not possible for the (?) The required modules because it's been on. So instead of just calling HostResolveImportedModule because ecma 262 has to give to the hospice chance, 2. guard the module, let's say at runtime, and this done using the HostImportModuleDynamically hook. So when it sees an import call, it. asked Ali host to learn to lot of that message. The. host starts all the graph searching of linking a selection process, which is exactly the same as before. And then it calls into ecma262 again using this abstract operation called FinishDynamicImport to say. hey I finish loading module, you can resolve the promise records. again, we have the same requirement for host import module and an equally as we have four streets of imported model. So if it's called multiple times and we try to run going and it succeeds, it has different tone, It has called for a national comport with the same amount of record.

NRO: Okay. so we have mostly seen how loading modules works, Why am I talking about this? There are different proposals related to module right now. One of them is module blocks which allows creating a modyke that potential imports other models, but the important thing is that this module is created inline. And so it's not created by the host. and, we can later dynamically import this module to trigger the loading and execution of all the dependencies. so, we will need a new host to look, for example I'm calling it HostLoadModuleDependencies to load the dependencies of a module that you already have.Then we have the import reflection proposal. That actually stopped. When it comes from JavaScript modules, it allows loading a module without actually loading dependencies and without executing it. So we need two new hosts hooks now, one to load the module without actually loading the dependencies and want to them later load. The dependencies of the module will auditor righteously. So one of these two hooks is the same as what we need for module blocks. The other is a fourth one. one. and, lastly, we have the compartments proposal. Compartments allow virtualizing The related host Behavior to the final module loader. It needs to specify how the graph loading process works by delegating the loading of a single module records to an async function.

NRO: so, can we avoid introducing all these new host hooks and duplicating the loading algorithm between ecma262 and hosts. Well, yes, we can introduce a new single hook that we can use for every single of those use cases are presented, which is an asynchronous version of HostResolveImportedModule. I called it HostLoadImportedModule, it takes a module specifier and then loads it and (?) without doing anything else. So, with this hook, how would loading and evaluating a module work? Well. first the host has to load the entry point. It can reuse the same logic that uses in host imported model. Then we have the again the graph loading phase but this time the graph loading phase is not managed by the Important. Is that it calls Lodge, requested modules method in equal to six books, Ahmed 262 to recursively load all the dependencies using this new host hook which might be asynchronous and stores. the result of each call to this hook into an internal cache. And this internal cache is made it so that later we can access these modules synchronously instead of calling the asynchronous host hook. and, this process is mostly all async. After. the graph loading phase, we have the graph linking phase. So the host calls the link method again. And this time, the link method iterates over all the modules in a graph without interacting with the host anymore, because we already have the module records in this inline cache . And finally, the whole starts the evaluation phase by calling the evaluating a do we evaluate method in 262 and again we iterate through the module graph and we evaluate all the modules. oh, Also, the evaluation phase does not call into host hooks anymore.

NRO: just for comparison. This was the old process, so you can see that the linking phase and the evaluation phase with the old hooks called into the host while get new ones don't.

NRO: And, how does dynamic import work with this new Hook? when 262 sees the dynamic import it calls the host hook to load the single top level module. The host sees that this top level, module 6, and, six to start salad, requested modules, link and evaluates process. where logic wasted models still has to call multiple times. The host took to load. All the dependencies the first time. And then it doesn't need to call it in host hooks anymore. anymore. and, finally 262 resolves the promise returned by the dynamic import.

NOR: How? does this help with all the module-related proposals? Well. module blocks can call this new LoadRequestedModules method to load all the dependencies of an inline module. and these other requested most record already does exactly that calling the host to look for every single dependency. Import reflection can call this hook to load a single module without loading its dependencies. And then it can process the return module record to provide the relevant results. And the compartments proposal can reuse the new (?) Introducing 262 by simply walking be called the first hook with a call to be user provided asynchronous function.

NRO: You can check the spec in the repository and we also have an HTML PR all ready for this. The HTML editors are on board with these changes. so, that's it for my presentation. I'm asking. I guess. I'm not sure this is a normative change or not because I'm not sure if changing host hooks is normative or not. If it is I would like to ask for consensus on this without waiting for the module proposals because this is already simplifies the interaction between 262 and HTML. And also, this allows the various proposals move more independently without being one based on the others. Okay. so let's go to the queue.

SYG. This is pretty great. Thanks so much for doing this work Niccolo. I want to make sure I understand the implications on the semantics. So please correct me if my understanding is wrong. Here's what I understand. In current hosts, in HTML, in node in deno, the - sorry, let me back up a bit. What your PR does is by unifying on this one hook, It moves some of the logic that is currently specified in the host side and moves it to the 262 side. So, in that sense, like more stuff is specified in 262, but the net effect on the hosts that embed 262 including HTML node and deno The net effect is that these changes are editorial in that, like, the hosts themselves, do not change any behavior. from 262s point of view. not knowing any hosts, we have specified more Behavior but as a whole, like, the actual hosts are editorial changes. Is that correct?

NRO: Yes. So hosts will still be able to do whatever they do. I try making sure of this even by like reducing the refactorings surface that would have liked to do to make sure that we can still describe the existing Behavior using this new logic. so, obvious from I like comprehensive point of view, they should just be editorial and the moves, the interaction layer between 262 and the hosts

SYG: Okay. then I would treat this. In fact, as editorial in that in the set of potential hosts in the world. sir in the set of potential hosts in like all possible worlds, this is normative. But in the actual world, where all the hosts, We can enumerate and check what their behavior is, this is actually editorial. So, I'm very happy with the editorial change. Thanks for presenting.

JWK: last time I checked out the related source on this PR, I saw something that said it is normative about how many promise ticks needed to load a module. It will change, but it will at most promise ticks what current hosts have. Is that correct?

NRO: So, yes. as like from my understanding of the current spec we currently require at least two. promised ticks, when doing the dymamic import because the host has await when calling FinishDynamicImport and then 262 awaits again on a separate promise. So, it should be less, two ticks and this refactor keeps that. actually 2 fixed limit. If like costs carefully call the new hook at the correct time. There. is also another way in which this does not change number of ticks. and I have a another slide that. So, which I'm not asking for consensus rom this right now, but it's relevant.

NRO: with this cache that we now have. We could avoid we're asking to The host to when loading the same module twice. So if we have the same dynamic import in a file, we could avoid calling the host hook again and this would mean that we can guarantee the exact number of mistakes. However, I found that browsers always yield to the event Loop even for loaded modules. So I removed this change from this refactor so the browser can continue building to be able to look in the in the case. so, yes, this does not change the observability of Promise takes in the(?). It would be this additional change.

RPR: Right. the queue is empty.

NRO: Okay. so what about classic is that That is it like process-wise? should I just open up here? like, if like after confirming that they casually? doesn't change the behavior? We can consider it as normal as editorial and those energy without asking for consensus come time.

KG: I would just ask for consensus for this change, interpreted somewhat broadly.

RPR: I think we're saying that in the actual world. we're considering this to be editorial. and you're asking for consensus to proceed with this PR

NRO: Yes.

RPR: So, any objections to going forwards with this PR

MM: We enthusiastically support this PR.

RPR: Thank you Mark. any other messages of support or objections?

JWK: I support this. It makes my implementation of the compartments proposal much easier.

RPR: Okay. NRO I think you have consensus here.

NRO: Thank you everyone.

### Conclusion/Resolution

- Consensus to pursue this refactoring

## R&T revisited

Presenter: Ashley Claymore (ACE)

- [proposal](https://github.com/tc39/proposal-record-tuple)
- [slides](https://docs.google.com/presentation/d/1R-vIEjohygNLljwevROUZF_7b7RmCY7MRsXCp_Wdvz8/edit)

ACE: So we're back. I think our 45-minute time box on Tuesday was ambitiously short for the amount of content that we had. So, really happy to have an extension here to close off this month's plenary. So, one thing we kind of whizzed over on our initial slides and didn't get around to talking about more was expanding on where we are with implementer feedback. So we are in active discussions with both the teams at Moddable and also Mozilla. So that's happening. We're still discussing which parts of this proposal could change. So we're kind of doing two things at once - we're discussing kind of fundamental parts of the proposal while also still imagining an alternative Universe where there aren't fundamental changes, the proposal remains similar to as it is. And we're also focusing on what are small little tweaks here and there. So we're discussing both the macro and the micro and don't want anyone to think that whenever we're talking about the micro. That's because we're ignoring the macro level. So, we haven't got any concrete macro changes at the moment it's more conversations that are happening. In terms of concrete things that we're interested in getting feedback on they are still more of the kind of micro nature changes to the current proposal, in the way that the spec is currently written. and we really do encourage people to reach out to us on matrix, by email, by Twitter, any of these communication methods. We're obviously very enthusiastic about this proposal, we keep setting ourselves targets of when we're going to ask for stage 3, and we keep pushing that back. But we do still keep imagining a world where we could go ask for stage 3 at the next meeting. Mostly just to keep our own motivation and momentum up, you know, not in a way to actually force through something that is not in any way ready.

ACE: So going now into actually the micro level changes to how the spec is currently written. Something that we talked about on Tuesday is what happens with the record wrapper objects. So, you have a record primitive and then it gets coerced to an object in some way. It makes its way to the ToObject operation and you get back the object. So right now in the spec you get back a Record exotic object. So this is an object that has an internal hidden slot `[[RecordValue]]` that still holds onto the original primitive. And then it has a set of custom internal methods to ensure that this object behaves appropriately. So when you look at properties, it gets delegated through to that internal primitive that it's holding onto. One outcome of this, as people that were there on Tuesday are aware, is that this kind of opens up the brand checking question of how do you check for the presence of that `[[RecordValue]]` slot? It's kind of not directly observable. You have to observe these slots by other means. KG raised an interesting idea that we hadn't previously thought about which was: what if, when you coerce these things to objects, you don't get back an exotic object. you just get back an ordinary object, similar to - for all intents and purposes, apart from a few small places, the object is effectively just a frozen object. The reason we talked about this for records and not tuples is because there's a lot more happening with a tuple. While records are collections of string keys to values, tuples have a lot more. So they have TypedArray-style indexing. So if you use integer-indexed access, then if you read out of bounds, it doesn't then delegate to the prototype: it stops and returns undefined. So you can't add an integer index onto `Tuple.prototype`, and then make that suddenly appear on all on all tuples. Then all other properties you look up are then forwarded on to the Prototype. So that's how you can get to the kind of symbol protocols and the tuple methods. we think this is a really important property of tuples when reasoning about their kind of immutability that you have this guaranteed action, that when you access `length` or an integer, you're guaranteed what you're going to get back. And there's no way that suddenly becomes dynamically related to the prototype. They're also different in that they have a prototype. So the methods on that prototype do all brand check, so you can't take Tuple.prototype.map and then call and pass in an array-like, if the Tuple object that gets created with ToObject wouldn't have this slot then that object wouldn't be usable. in terms of you wouldn't be able to dot access the methods and use them because the receiver would be a plain object which wouldn't pass the brand check and would throw. So we think it's important that tuples do keep their special wrapper object, and, it's also ok in that that they don't hit this issue of not having a way of brand checking.

ACE: So, the `ToObject` operation appears in a few places. so if you have a sloppy function that's called with a primitive as the receiver, then within the execution of that function, the primitive is being passed to ToObject. There's also kind of explicitly passing the primitive to the `Object` constructor as a function call, and there's a few other little places that it can pop up. Usually when primitives get coerced to their objects, a common way you can brand check for these is using one of their prototype methods and calling it and you can try-catch around that to assert - you can check if it's going to have that internal slot because all these methods will throw. The issue of Records is that not having a prototype, not having any methods, not really having any static methods, there's not really been a clear place where this brand check can be. So we've kind of looked in lots of ways and we are actually - stepping back and looking at KG's suggestion: just not having a record exotic object in the first place it kind of completely sidesteps this issue. If there is no brand to check then there isn’t a brand-check that is missing in the first place. Which is why we think this is quite an interesting way to solve this.

AC:E So, if I just drop over to the actual [PR](https://github.com/tc39/proposal-record-tuple/pull/357). The PR effectively deletes a lot of code, it deletes like, three hundred lines of code and adds 30. and it means that we completely remove the record exotic object, the one that has its own implementations of DefineProperty. GetOwnProperty, HasProperty, Get etc. It removes all of those things. and, instead when a record is passed to `ToObject`, we just create an ordinary object with a null prototype, we copy all the properties and their values from the record primitive into that object, and then we freeze that object. Implementers don't necessarily have to do that, they could still do things more efficiently. But from a spec perspective, you know, it would be a kind of a linear copy and perhaps that's what implementers do, there's no expectation that they would optimize that but they are free to optimize it if they so choose.

ACE: I can see SYG on the queue, asking if the copy is shallow.

ACE: Yes, it is shallow. The exotic wrapper was also shallow as well. In the exotic wrapper the object is effectively empty. The only thing it had are the internal methods and the internal slot holding the primitive, and then when you look up a property, it looked up the field on the record and returns that value. That value you get back would be primitive again.

ACE: So, the observable aspects of going into this world where there is no exotic object and it's just a plain frozen object. Is that you kind of lose the places where we previously had custom dispatch on that slot. So those places were the `ToPrimitive` operation, `ToString` operation, and `Object.prototype.toString.call`. So, before, when you try to concatenate a string and a record object, the record object would be coerced back to the primitive by the `ToPrimitive` operation, and then that would then just go into the usual `ToString` for a record primitive which as we agreed on Tuesday now gives you this nice detailed string. Also if you try to do a sloppy comparison, `#{} == recordObject`, this used to return `true`, because again you'd hit the `ToPrimitive` of the object and it was turned into the primitive and then that compares directly. And, then also `Object.prototype.toString` used to look for that internal slot and would set the tag to “Record”. We now TypeError on those things, exactly the same way you would type error if you if you were using `Object.create(null)`. because all of these operations, without the presence of that slot are going to look for things like `Symbol.toPrimitive`, the `toString` method, the `valueOf` method and all of those things will now be missing. Just like `Object.create(null)`. So they will TypeError. We think that is okay, because we think these things are potentially errors in your code. And you also then lose the “Record” StringTag, but again this is kind of somewhat intuitive and makes sense because the record, when you convert to an object, we are saying you do just get back a plain object. so we think it's somewhat intuitive that you now get back “[object Object]”. A nice thing that we don't lose is that previously when we had our ToString operation, we still ensure that records don't implicitly become allowable as object keys, they won't implicitly be coerced to Strings here. That is still retained because we hit the `ToString` operation and that throws. So, they are the observable differences when code ends up dealing with object wrappers, which we think that already is a bit of an edge case and then when code tries to do one of these operations all hit a TypeError. We think those are all worth this kind of large simplification of the proposal. Thanks. Yeah. Happy to go to the queue.

JHD: If this Frozen object was given an own `Symbol.toPrimitive` frozen function, that just spit the record right back out. Wouldn't that restore a lot of those before behaviors?

ACE: Yeah. so we could we could install that symbol. The consequence of that would be that if someone has a record primitive and then they did then now try to look up `Symbol.to Primitive` that would also - it would be as if that symbol also existed on the primitive, which is perhaps fine. It's just a - the fact that whenever you interact with the primitive, it gets coerced to the object to do the look up. Says, if these things exist there but I think maybe that is actually a good thing. I mean, overall

JHD: I don't I mean there's a few options there, right? Like the, symbol to primitive method. I'm describing could exist on record Primitives for consistency, but I don't think it needs to be getting would be fine if it was only on the object form. Because if you pass it, The. wreckage Constructor, it's just going to get dropped anyway. But the other thing is that these lists of befores, I agree that all of - at least the two of these three before things are almost certainly bugs in the code, so I'm less concerned about those as I am about the object prototype tostring output. So it might even be… I don't know. It's I haven't obviously we can talk about this on the PR but I am I'm happy when foot guns can be avoided, but I would prefer debugging output for a box to record, or for the frozen object, it's out to be equally useful as for a primitive record. That will make sense.

ACE: your preference would be that those things work?

JHD: Yeah. So I'll restate I haven't come to a certain conclusion yet because I haven't read through this PR because we're the middle. plenary. But it seems like Kevin's suggestion here, if it also remained useful for it, if it retained the useful properties for debugging that a record primitive has it seems like this obviates a lot of the otherwise sticking points that we've here around boxed records, and it sounds like it'll be a really good path forward. So I'm hopeful that between now and the next meeting, we can keep exploring this and see if we can figure out a way to retain that debuggable usefulness on a boxed record.

ACE: One thing, I guess MM is on the call, maybe he's already noticed this. What if we did automatically add Symbol to primitive on the object. That would create a new hidden intrinsic.

JHD: so, because if it would have to be a newly created function every time, because the record primitive it returns would be different and less the implementation of it was just the record Constructor on the receiver or something. and obviously if it's a shared function then yes, it's a new hidden intrinsic. And if it's a custom function every time, then it would have to be frozen. but that's I think that's something we can explore between the plenaries.

ACE: Yes. Good point. I hadn't realized it could also be a new function every time that's a good point.

KG: So, Jordan, you mentioned debugging. You expect this to come up when debugging?

JHD: It comes. up so frequently that everything that I've seen in the ecosystem that attempts to discuss to describe a value for debugging purposes, including the object-inspect module that I maintain, and node itself, they all provide custom or and browser Rebels, they all provide custom descriptions that are different between a It. motive and the Box primitive because it's important in debugging to know when you have box primitive. It admittedly is almost always a mistake to have one but that's why it's so important to know that you do.

KG: so, it's a lot easier to end up with a boxed string, because you can do `new String` whereas you cannot do `new Record`. So I am not convinced that these are likely to actually come up in real life enough to be worth worrying about how to debug them.

JHD: and that is fair. The only primitive the only primitives you cannot new are BigInt and symbol and yet both of these still were requested via users, like I like at least I think maybe for me, one of them I did optimistically in the other one. I wait, you know, someone asked me for it. So it did happen for somebody. maybe they were just out, okay? See. I agree with you that it is likely to be more rare because the majority of the time people have box, Primitives is likely because of their trying to just cargo cult that new primitive Constructor pattern from another language. But the fact that these values can exist means they're worth being shown, and I the approach you suggested here has the advantage that it's no longer exotic, which means that you could argue, as I see Dan is doing on the Queue that perhaps it's just a normal object, it doesn't need any special description. but, given that it originated from a record primitive, that is much more likely to be valuable to know that it came from a record primitive. As. opposed to an object literal, which could come from or any other plain object, which can come from literally anywhere. I agree. This is an edge case and I'm not trying to say this is like, a very important. Yeah as I guess you could use part of the language it. Go ahead.

ACE: Another perspective is a similar thing would be that if I spread a record into an object, that object came from the record primitive but it's now no longer directly associated. It's just a plain ordinary object from that point and I guess that's what we're kind of saying here. When the record gets turned into an object, an object is created. But from that point on it, it's no different to an object that was manually created by other means it's not special in any way, it is what it is. So it's ok, that it behaves exactly like all other objects that are created in this manner, it debugs exactly the same way as `Object.create(null)` and adding properties and freezing it.

JHD: I accepted it that the case that it is in fact the same object, but I'm saying that nobody is accidentally spreading going accidentally spread a record into an object and be surprised like they're expecting to get an object out there are you know, as there are still people that write sloppy mode code, there are still know, people that pass things through the object Constructor and like the object function, and I do I think that there will be cases when people accidentally box a record or convert a record to an object even with this PR and I think it would be You. Useful to be able to know that.

DE: There's three things I want to separate here. One is. these three qualities that are mentioned in the PR that differ between the Frozen object and not any other is you know, being able to check the the providence of a boxed record, or record converted to an object. So for these three I'm pretty skeptical of the ToPrimitive thing. You know, we got into some of those reasons why having an own method would be complicated. And I'm not really. understanding exactly why these cases need to be handled in such a kind of a perfect way. If they are handled differently, clearly we would have to somehow mark that object and then you could kind of test for that marking. If they're not handled in this other way, we were just talking about the provenance of an object, and if you if we're talking about debugging tools that have ways of inspecting objects, presumably, they would be able to deal with frozen objects and I think that should be enough.

KG: I agree that someone will at some point encounter an object that they got from coercing a record to an object. I think that this will happen so rarely that I don't want us to spend hardly any effort in the language helping out that case.

MM: So I'm very interested in supporting understandability and debuggability on the of the programmer experience for people who are programmers writing strict mode code. For people who are programming sloppy mode code can't figure out what their program is doing the first thing they should do is switch to strict mode, and until they do that, I don't have any sympathy for their difficulty in understanding their code. I'm certainly not willing to pay complexity cost to the language as a whole in order to support the understand ability to somebody writing sloppy code.

JHD: My reply to that. Is that anytime you use third-party code, which in modern JavaScript is almost all the time, you are using code that you don't control, that may or may not be written, and in sloppy mode. So, I agree with you that individuals first party code. I completely agree with you but that is not often enough.

MM: that's a good answer. That's a good that's a valid answer. I think that as we've encountered various sloppy mode programs, we found that there's very little work to convert them to strict mode but it but it's that's certainly different than just linking in some third party Library. Okay. Thank you.

WH: In the modified proposal how do you write a function which can figure it out if its argument is a primitive record?

ACE: For that you can just use typeof. typeof would return the string "record". And that's how, you know you've got the actual real primitive value.

RBN: Yeah, I brought this up in the matrix chat. If I'm reading what It's showing here, correctly. There's the potential that something double equals something can throw. If those two things are built in, values without prototype modification. I mean, yes, double equals throw if you have a bad to primitive, or if you have a bad valueOf etc, but there is no built-in in the language today. Primitive object function or otherwise. we're double equals throws without somebody mutating the Prototype?

ACE: Don't module name spaces, they only have symbol to string tag and a null prototype.

RBN: That way, I can convince you, that, that was something that was the case. But know that the double equals null is a frequent comparison. That folks do if they have a binding that exist and they just want to check if it's null or undefined despite the document.all and

ACE: The reason it throws is because we're comparing it to something specific, it’s I'm comparing it to a record primitive so, that's what's that's what's triggering the `toPrimitive` operation. It wouldn't throw if I did `== null`l.

BRN: Okay. Yeah. so yeah,

ACE: it's specifically which path of the `==` AO we're hitting.

JHD: also the groups object on regular expression match object.

RBN: I, also probably use the previous argument here as well. That these objects are less common which may impact our thinking here, because I mean while they do appear you know, it's not an expected outcome. So, if you are receiving it in strict mode code a wrapped record when you don't expect it, I'm fine with that. But ACE is also looking at what they expect us.

BT: I think we're at time. Are the champions going to call for any consensus?

ACE: We would hope we plan to merge this PR you know, as part of a kind of stage 2 design of putting this back together, if people do have really strong objections - there's no rush in us merging the PR, we can leave it open, say, for a week, if people can continue the discussion on the PR. Our position is that we are still in favor of this PR, and also happy to continue the conversation.

BT: All right. Thank you.

ACE: Thank you.

### Conclusion/Resolution

- Champions plan to merge PR sometime soon

## Incubator calls

Presenter: Shu-yu Guo (SYG)

SYG: am not proposing any new ones myself. We meant when I made some time to run. one incubator called between last meeting and this meeting for a decorator meta data. So we can strike that off of the current charter. So the remaining proposals on the charter, which will carry over is BigIntMath round 2, pipeline, and object.pick and .omit. So, while there are interesting things that came up in this meeting that I think would benefit from having an incubator call, just to be realistic I don't think adding to the a to be charter wouldn't actually be drained anytime soon. so I'm not proposing anything new, so with that. So, the floor to folks who want to volunteer to be added to the charter.

SYG: Judging by the silence, I'm going to assume no takers. so I'll end with another call to - if you are interested in any of those topics on the charter. Well, that's not a good. That's not a good pitch because we're if you're interested you presumably want to participate not to run the meeting which makes it harder to participate. but if there are any folks are interested in running, incubator calls to help drain the queue faster. That would be much appreciated.
